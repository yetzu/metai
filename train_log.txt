nohup: ignoring input
--------------------------------------------------------
 [MetAI] Starting Training (Phase: Physics -> Sparse -> GAN) ...
--------------------------------------------------------
Seed set to 42
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/3
[rank: 2] Seed set to 42
[rank: 1] Seed set to 42
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/3
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/3
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 3 processes
----------------------------------------------------------------------------------------------------

NCCL version 2.27.3+cuda12.9
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/utilities/model_summary/model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.

  | Name              | Type                | Params | Mode 
------------------------------------------------------------------
0 | model             | MeteoMamba          | 24.1 M | train
1 | criterion_content | HybridLoss          | 5      | train
2 | criterion_gan     | GANLoss             | 0      | train
3 | train_metrics     | MetMetricCollection | 0      | train
4 | val_metrics       | MetMetricCollection | 0      | train
5 | test_metrics      | MetMetricCollection | 0      | train
------------------------------------------------------------------
24.1 M    Trainable params
0         Non-trainable params
24.1 M    Total params
96.428    Total estimated model params size (MB)
294       Modules in train mode
0         Modules in eval mode
[2025-12-05 00:48:40.830] [INFO] Loading configuration from file: /home/yyj/code/metai/config.yaml
[2025-12-05 00:48:40.928] [INFO] Dataset split: Train=8011, Val=1001, Test=1002
Sanity Checking: |          | 0/? [00:00<?, ?it/s][2025-12-05 00:48:40.831] [INFO] Loading configuration from file: /home/yyj/code/metai/config.yaml
[2025-12-05 00:48:40.927] [INFO] Dataset split: Train=8011, Val=1001, Test=1002
[2025-12-05 00:48:40.830] [INFO] Loading configuration from file: /home/yyj/code/metai/config.yaml
[2025-12-05 00:48:40.926] [INFO] Dataset split: Train=8011, Val=1001, Test=1002
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s][rank0]: Traceback (most recent call last):
[rank0]:   File "/home/yyj/code/run/train_scwds_mamba.py", line 24, in <module>
[rank0]:     main()
[rank0]:   File "/home/yyj/code/run/train_scwds_mamba.py", line 16, in main
[rank0]:     cli = LightningCLI(
[rank0]:           ^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/cli.py", line 414, in __init__
[rank0]:     self._run_subcommand(self.subcommand)
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/cli.py", line 747, in _run_subcommand
[rank0]:     fn(**fn_kwargs)
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 560, in fit
[rank0]:     call._call_and_handle_interrupt(
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py", line 48, in _call_and_handle_interrupt
[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank0]:     return function(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 598, in _fit_impl
[rank0]:     self._run(model, ckpt_path=ckpt_path)
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 1011, in _run
[rank0]:     results = self._run_stage()
[rank0]:               ^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 1053, in _run_stage
[rank0]:     self._run_sanity_check()
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 1082, in _run_sanity_check
[rank0]:     val_loop.run()
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/loops/utilities.py", line 179, in _decorator
[rank0]:     return loop_run(self, *args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 145, in run
[rank0]:     self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 437, in _evaluation_step
[rank0]:     output = call._call_strategy_hook(trainer, hook_name, *step_args)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py", line 329, in _call_strategy_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py", line 411, in validation_step
[rank0]:     return self._forward_redirection(self.model, self.lightning_module, "validation_step", *args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py", line 641, in __call__
[rank0]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank0]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1648, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1474, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py", line 634, in wrapped_forward
[rank0]:     out = method(*_args, **_kwargs)
[rank0]:           ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/code/metai/model/met_mamba/trainer.py", line 182, in validation_step
[rank0]:     loss, _ = self.criterion_content(y_hat, y, flow=flows, prev_frame=prev_frame, mask=y_mask)
[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/code/metai/model/met_mamba/loss.py", line 293, in forward
[rank0]:     l_cons, l_warp = self.loss_physics(pred, target, flow, prev_frame, mask)
[rank0]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/yyj/code/metai/model/met_mamba/loss.py", line 175, in forward
[rank0]:     B, T, C, H, W = tgt_imgs.shape
[rank0]:     ^^^^^^^^^^^^^
[rank0]: ValueError: not enough values to unpack (expected 5, got 4)
[rank2]:[W1205 00:49:01.767421137 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=54, addr=[localhost]:37618, remote=[localhost]:33287): Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:682 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x790d03ad9eb0 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5d694f1 (0x790ce73694f1 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5d6a8ed (0x790ce736a8ed in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5d6b49a (0x790ce736b49a in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x790ce73661be in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x790c8ba70598 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x790c6eedbbf4 in /home/yyj/opt/anaconda3/envs/metai/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x790d04a9caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c6c (0x790d04b29c6c in /lib/x86_64-linux-gnu/libc.so.6)

[rank2]:[W1205 00:49:01.772308533 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 2] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
[rank1]:[W1205 00:49:01.020698959 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=54, addr=[localhost]:37626, remote=[localhost]:33287): Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:682 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7a549937eeb0 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5d694f1 (0x7a547cb694f1 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5d6a8ed (0x7a547cb6a8ed in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5d6b49a (0x7a547cb6b49a in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7a547cb661be in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7a5421270598 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7a54046dbbf4 in /home/yyj/opt/anaconda3/envs/metai/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x7a549a29caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c6c (0x7a549a329c6c in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W1205 00:49:01.026256718 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
[rank2]:[W1205 00:49:02.772543067 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=54, addr=[localhost]:37618, remote=[localhost]:33287): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x790d03ad9eb0 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5d694f1 (0x790ce73694f1 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5d69d82 (0x790ce7369d82 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5d6b88e (0x790ce736b88e in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x790ce73661ae in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x790c8ba70598 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x790c6eedbbf4 in /home/yyj/opt/anaconda3/envs/metai/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x790d04a9caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c6c (0x790d04b29c6c in /lib/x86_64-linux-gnu/libc.so.6)

[rank2]:[W1205 00:49:02.777151716 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 2] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank1]:[W1205 00:49:02.026593197 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=54, addr=[localhost]:37626, remote=[localhost]:33287): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7a549937eeb0 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5d694f1 (0x7a547cb694f1 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5d69d82 (0x7a547cb69d82 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5d6b88e (0x7a547cb6b88e in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7a547cb661ae in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7a5421270598 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7a54046dbbf4 in /home/yyj/opt/anaconda3/envs/metai/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x7a549a29caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c6c (0x7a549a329c6c in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W1205 00:49:02.032418083 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank2]:[W1205 00:49:03.777365358 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=54, addr=[localhost]:37618, remote=[localhost]:33287): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x790d03ad9eb0 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5d694f1 (0x790ce73694f1 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5d69d82 (0x790ce7369d82 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5d6b88e (0x790ce736b88e in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x790ce73661ae in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x790c8ba70598 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x790c6eedbbf4 in /home/yyj/opt/anaconda3/envs/metai/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x790d04a9caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c6c (0x790d04b29c6c in /lib/x86_64-linux-gnu/libc.so.6)

[rank2]:[W1205 00:49:03.783023896 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 2] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank1]:[W1205 00:49:03.032641472 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=54, addr=[localhost]:37626, remote=[localhost]:33287): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7a549937eeb0 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5d694f1 (0x7a547cb694f1 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5d69d82 (0x7a547cb69d82 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5d6b88e (0x7a547cb6b88e in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7a547cb661ae in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7a5421270598 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7a54046dbbf4 in /home/yyj/opt/anaconda3/envs/metai/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x7a549a29caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c6c (0x7a549a329c6c in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W1205 00:49:03.038108552 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank2]:[W1205 00:49:04.783250506 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=54, addr=[localhost]:37618, remote=[localhost]:33287): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x790d03ad9eb0 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5d694f1 (0x790ce73694f1 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5d69d82 (0x790ce7369d82 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5d6b88e (0x790ce736b88e in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x790ce73661ae in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x790c8ba70598 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x790c6eedbbf4 in /home/yyj/opt/anaconda3/envs/metai/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x790d04a9caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c6c (0x790d04b29c6c in /lib/x86_64-linux-gnu/libc.so.6)

[rank2]:[W1205 00:49:04.787888515 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 2] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank1]:[W1205 00:49:04.038381428 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=54, addr=[localhost]:37626, remote=[localhost]:33287): Broken pipe
Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7a549937eeb0 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x5d694f1 (0x7a547cb694f1 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #2: <unknown function> + 0x5d69d82 (0x7a547cb69d82 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #3: <unknown function> + 0x5d6b88e (0x7a547cb6b88e in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7a547cb661ae in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7a5421270598 in /home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdbbf4 (0x7a54046dbbf4 in /home/yyj/opt/anaconda3/envs/metai/bin/../lib/libstdc++.so.6)
frame #7: <unknown function> + 0x9caa4 (0x7a549a29caa4 in /lib/x86_64-linux-gnu/libc.so.6)
frame #8: <unknown function> + 0x129c6c (0x7a549a329c6c in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[W1205 00:49:04.042982898 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0(default_pg) Rank 1] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/yyj/code/run/train_scwds_mamba.py", line 24, in <module>
[rank2]:     main()
[rank2]:   File "/home/yyj/code/run/train_scwds_mamba.py", line 16, in main
[rank2]:     cli = LightningCLI(
[rank2]:           ^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/cli.py", line 414, in __init__
[rank2]:     self._run_subcommand(self.subcommand)
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/cli.py", line 747, in _run_subcommand
[rank2]:     fn(**fn_kwargs)
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 560, in fit
[rank2]:     call._call_and_handle_interrupt(
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py", line 48, in _call_and_handle_interrupt
[rank2]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank2]:     return function(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 598, in _fit_impl
[rank2]:     self._run(model, ckpt_path=ckpt_path)
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 1011, in _run
[rank2]:     results = self._run_stage()
[rank2]:               ^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 1053, in _run_stage
[rank2]:     self._run_sanity_check()
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 1082, in _run_sanity_check
[rank2]:     val_loop.run()
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/loops/utilities.py", line 179, in _decorator
[rank2]:     return loop_run(self, *args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 145, in run
[rank2]:     self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 437, in _evaluation_step
[rank2]:     output = call._call_strategy_hook(trainer, hook_name, *step_args)
[rank2]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py", line 329, in _call_strategy_hook
[rank2]:     output = fn(*args, **kwargs)
[rank2]:              ^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py", line 411, in validation_step
[rank2]:     return self._forward_redirection(self.model, self.lightning_module, "validation_step", *args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py", line 641, in __call__
[rank2]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank2]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1648, in forward
[rank2]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank2]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1474, in _run_ddp_forward
[rank2]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py", line 634, in wrapped_forward
[rank2]:     out = method(*_args, **_kwargs)
[rank2]:           ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/code/metai/model/met_mamba/trainer.py", line 182, in validation_step
[rank2]:     loss, _ = self.criterion_content(y_hat, y, flow=flows, prev_frame=prev_frame, mask=y_mask)
[rank2]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/code/metai/model/met_mamba/loss.py", line 293, in forward
[rank2]:     l_cons, l_warp = self.loss_physics(pred, target, flow, prev_frame, mask)
[rank2]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/yyj/code/metai/model/met_mamba/loss.py", line 175, in forward
[rank2]:     B, T, C, H, W = tgt_imgs.shape
[rank2]:     ^^^^^^^^^^^^^
[rank2]: ValueError: not enough values to unpack (expected 5, got 4)
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/yyj/code/run/train_scwds_mamba.py", line 24, in <module>
[rank1]:     main()
[rank1]:   File "/home/yyj/code/run/train_scwds_mamba.py", line 16, in main
[rank1]:     cli = LightningCLI(
[rank1]:           ^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/cli.py", line 414, in __init__
[rank1]:     self._run_subcommand(self.subcommand)
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/cli.py", line 747, in _run_subcommand
[rank1]:     fn(**fn_kwargs)
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 560, in fit
[rank1]:     call._call_and_handle_interrupt(
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py", line 48, in _call_and_handle_interrupt
[rank1]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank1]:     return function(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 598, in _fit_impl
[rank1]:     self._run(model, ckpt_path=ckpt_path)
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 1011, in _run
[rank1]:     results = self._run_stage()
[rank1]:               ^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 1053, in _run_stage
[rank1]:     self._run_sanity_check()
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 1082, in _run_sanity_check
[rank1]:     val_loop.run()
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/loops/utilities.py", line 179, in _decorator
[rank1]:     return loop_run(self, *args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 145, in run
[rank1]:     self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 437, in _evaluation_step
[rank1]:     output = call._call_strategy_hook(trainer, hook_name, *step_args)
[rank1]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py", line 329, in _call_strategy_hook
[rank1]:     output = fn(*args, **kwargs)
[rank1]:              ^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py", line 411, in validation_step
[rank1]:     return self._forward_redirection(self.model, self.lightning_module, "validation_step", *args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py", line 641, in __call__
[rank1]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank1]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1648, in forward
[rank1]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank1]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/parallel/distributed.py", line 1474, in _run_ddp_forward
[rank1]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py", line 634, in wrapped_forward
[rank1]:     out = method(*_args, **_kwargs)
[rank1]:           ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/code/metai/model/met_mamba/trainer.py", line 182, in validation_step
[rank1]:     loss, _ = self.criterion_content(y_hat, y, flow=flows, prev_frame=prev_frame, mask=y_mask)
[rank1]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/code/metai/model/met_mamba/loss.py", line 293, in forward
[rank1]:     l_cons, l_warp = self.loss_physics(pred, target, flow, prev_frame, mask)
[rank1]:                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/yyj/code/metai/model/met_mamba/loss.py", line 175, in forward
[rank1]:     B, T, C, H, W = tgt_imgs.shape
[rank1]:     ^^^^^^^^^^^^^
[rank1]: ValueError: not enough values to unpack (expected 5, got 4)
 Operation Completed.
