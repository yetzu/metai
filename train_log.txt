nohup: ignoring input
--------------------------------------------------------
üöÄ [4x A800] ÂºÄÂßãËÆ≠ÁªÉ MeteoMamba Âü∫Â∫ßÊ®°Âûã (BF16 Mixed)...
--------------------------------------------------------
Seed set to 42
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
[rank: 3] Seed set to 42
[rank: 1] Seed set to 42
[rank: 2] Seed set to 42
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

NCCL version 2.27.3+cuda12.9
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/utilities/model_summary/model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.

  | Name      | Type       | Params | Mode 
-------------------------------------------------
0 | model     | MeteoMamba | 9.2 M  | train
1 | criterion | HybridLoss | 0      | train
-------------------------------------------------
9.2 M     Trainable params
0         Non-trainable params
9.2 M     Total params
36.974    Total estimated model params size (MB)
248       Modules in train mode
0         Modules in eval mode
[2025-11-26 23:37:40.502] [INFO] ‰ªéÈÖçÁΩÆÊñá‰ª∂Âä†ËΩΩÈÖçÁΩÆ: /home/yyj/code/metai/config.yaml (is_debug=False)
[2025-11-26 23:37:41.477] [INFO] Dataset split: Train=15160, Val=1895, Test=1895
Sanity Checking: |          | 0/? [00:00<?, ?it/s][2025-11-26 23:37:40.501] [INFO] ‰ªéÈÖçÁΩÆÊñá‰ª∂Âä†ËΩΩÈÖçÁΩÆ: /home/yyj/code/metai/config.yaml (is_debug=False)
[2025-11-26 23:37:41.221] [INFO] Dataset split: Train=15160, Val=1895, Test=1895
[2025-11-26 23:37:40.501] [INFO] ‰ªéÈÖçÁΩÆÊñá‰ª∂Âä†ËΩΩÈÖçÁΩÆ: /home/yyj/code/metai/config.yaml (is_debug=False)
[2025-11-26 23:37:41.109] [INFO] Dataset split: Train=15160, Val=1895, Test=1895
[2025-11-26 23:37:40.500] [INFO] ‰ªéÈÖçÁΩÆÊñá‰ª∂Âä†ËΩΩÈÖçÁΩÆ: /home/yyj/code/metai/config.yaml (is_debug=False)
[2025-11-26 23:37:41.097] [INFO] Dataset split: Train=15160, Val=1895, Test=1895
