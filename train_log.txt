nohup: ignoring input
--------------------------------------------------------
 [MetAI] Starting Training (Phase: Physics -> Sparse -> GAN) ...
--------------------------------------------------------
Seed set to 42
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/3
[rank: 1] Seed set to 42
[rank: 2] Seed set to 42
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/3
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/3
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 3 processes
----------------------------------------------------------------------------------------------------

NCCL version 2.27.3+cuda12.9
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/utilities/model_summary/model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.

  | Name              | Type                | Params | Mode 
------------------------------------------------------------------
0 | model             | MeteoMamba          | 24.1 M | train
1 | criterion_content | HybridLoss          | 5      | train
2 | criterion_gan     | GANLoss             | 0      | train
3 | train_metrics     | MetMetricCollection | 0      | train
4 | val_metrics       | MetMetricCollection | 0      | train
5 | test_metrics      | MetMetricCollection | 0      | train
------------------------------------------------------------------
24.1 M    Trainable params
0         Non-trainable params
24.1 M    Total params
96.428    Total estimated model params size (MB)
294       Modules in train mode
0         Modules in eval mode
[2025-12-05 00:59:59.301] [INFO] Loading configuration from file: /home/yyj/code/metai/config.yaml
[2025-12-05 00:59:59.400] [INFO] Dataset split: Train=8011, Val=1001, Test=1002
Sanity Checking: |          | 0/? [00:00<?, ?it/s][2025-12-05 00:59:59.302] [INFO] Loading configuration from file: /home/yyj/code/metai/config.yaml
[2025-12-05 00:59:59.402] [INFO] Dataset split: Train=8011, Val=1001, Test=1002
[2025-12-05 00:59:59.303] [INFO] Loading configuration from file: /home/yyj/code/metai/config.yaml
[2025-12-05 00:59:59.407] [INFO] Dataset split: Train=8011, Val=1001, Test=1002
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:12<00:12,  0.08it/s]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:14<00:00,  0.14it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training: |          | 0/? [00:00<?, ?it/s]Epoch 0:   0%|          | 0/668 [00:00<?, ?it/s]/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/autograd/graph.py:829: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1024, 1, 3, 3], strides() = [9, 1, 3, 1]
bucket_view.sizes() = [1024, 1, 3, 3], strides() = [9, 9, 3, 1] (Triggered internally at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:334.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/autograd/graph.py:829: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1024, 1, 3, 3], strides() = [9, 1, 3, 1]
bucket_view.sizes() = [1024, 1, 3, 3], strides() = [9, 9, 3, 1] (Triggered internally at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:334.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/autograd/graph.py:829: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1024, 1, 3, 3], strides() = [9, 1, 3, 1]
bucket_view.sizes() = [1024, 1, 3, 3], strides() = [9, 9, 3, 1] (Triggered internally at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:334.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Epoch 0:   0%|          | 1/668 [01:10<13:02:00,  0.01it/s]Epoch 0:   0%|          | 1/668 [01:10<13:03:17,  0.01it/s, v_num=5, train_loss_g_step=0.544]Epoch 0:   0%|          | 2/668 [01:15<6:59:04,  0.03it/s, v_num=5, train_loss_g_step=0.544] Epoch 0:   0%|          | 2/668 [01:15<6:59:04,  0.03it/s, v_num=5, train_loss_g_step=0.767]Epoch 0:   0%|          | 3/668 [01:20<4:55:52,  0.04it/s, v_num=5, train_loss_g_step=0.767]Epoch 0:   0%|          | 3/668 [01:20<4:55:52,  0.04it/s, v_num=5, train_loss_g_step=0.630]Epoch 0:   1%|          | 4/668 [01:27<4:02:55,  0.05it/s, v_num=5, train_loss_g_step=0.630]Epoch 0:   1%|          | 4/668 [01:27<4:02:55,  0.05it/s, v_num=5, train_loss_g_step=0.685]Epoch 0:   1%|          | 5/668 [01:33<3:27:33,  0.05it/s, v_num=5, train_loss_g_step=0.685]Epoch 0:   1%|          | 5/668 [01:33<3:27:33,  0.05it/s, v_num=5, train_loss_g_step=0.732]Epoch 0:   1%|          | 6/668 [01:39<3:02:03,  0.06it/s, v_num=5, train_loss_g_step=0.732]Epoch 0:   1%|          | 6/668 [01:39<3:02:03,  0.06it/s, v_num=5, train_loss_g_step=0.620]Epoch 0:   1%|          | 7/668 [01:43<2:43:01,  0.07it/s, v_num=5, train_loss_g_step=0.620]Epoch 0:   1%|          | 7/668 [01:43<2:43:01,  0.07it/s, v_num=5, train_loss_g_step=0.336]Epoch 0:   1%|          | 8/668 [01:48<2:28:39,  0.07it/s, v_num=5, train_loss_g_step=0.336]Epoch 0:   1%|          | 8/668 [01:48<2:28:39,  0.07it/s, v_num=5, train_loss_g_step=0.351]Epoch 0:   1%|▏         | 9/668 [01:53<2:19:05,  0.08it/s, v_num=5, train_loss_g_step=0.351]Epoch 0:   1%|▏         | 9/668 [01:53<2:19:06,  0.08it/s, v_num=5, train_loss_g_step=0.495]Epoch 0:   1%|▏         | 10/668 [01:59<2:10:49,  0.08it/s, v_num=5, train_loss_g_step=0.495]Epoch 0:   1%|▏         | 10/668 [01:59<2:10:49,  0.08it/s, v_num=5, train_loss_g_step=0.546]Epoch 0:   2%|▏         | 11/668 [02:05<2:04:39,  0.09it/s, v_num=5, train_loss_g_step=0.546]Epoch 0:   2%|▏         | 11/668 [02:05<2:04:39,  0.09it/s, v_num=5, train_loss_g_step=0.496]Epoch 0:   2%|▏         | 12/668 [02:11<1:59:30,  0.09it/s, v_num=5, train_loss_g_step=0.496]Epoch 0:   2%|▏         | 12/668 [02:11<1:59:30,  0.09it/s, v_num=5, train_loss_g_step=0.526]Epoch 0:   2%|▏         | 13/668 [02:16<1:55:01,  0.09it/s, v_num=5, train_loss_g_step=0.526]Epoch 0:   2%|▏         | 13/668 [02:16<1:55:01,  0.09it/s, v_num=5, train_loss_g_step=0.451]Epoch 0:   2%|▏         | 14/668 [02:24<1:52:20,  0.10it/s, v_num=5, train_loss_g_step=0.451]Epoch 0:   2%|▏         | 14/668 [02:24<1:52:20,  0.10it/s, v_num=5, train_loss_g_step=0.414]Epoch 0:   2%|▏         | 15/668 [02:30<1:48:51,  0.10it/s, v_num=5, train_loss_g_step=0.414]Epoch 0:   2%|▏         | 15/668 [02:30<1:48:51,  0.10it/s, v_num=5, train_loss_g_step=0.512]Epoch 0:   2%|▏         | 16/668 [02:36<1:46:34,  0.10it/s, v_num=5, train_loss_g_step=0.512]Epoch 0:   2%|▏         | 16/668 [02:36<1:46:34,  0.10it/s, v_num=5, train_loss_g_step=0.484]Epoch 0:   3%|▎         | 17/668 [02:41<1:42:49,  0.11it/s, v_num=5, train_loss_g_step=0.484]Epoch 0:   3%|▎         | 17/668 [02:41<1:42:49,  0.11it/s, v_num=5, train_loss_g_step=0.377]Epoch 0:   3%|▎         | 18/668 [02:47<1:40:38,  0.11it/s, v_num=5, train_loss_g_step=0.377]Epoch 0:   3%|▎         | 18/668 [02:47<1:40:45,  0.11it/s, v_num=5, train_loss_g_step=0.334]Epoch 0:   3%|▎         | 19/668 [02:55<1:40:04,  0.11it/s, v_num=5, train_loss_g_step=0.334]Epoch 0:   3%|▎         | 19/668 [02:55<1:40:04,  0.11it/s, v_num=5, train_loss_g_step=0.544]Epoch 0:   3%|▎         | 20/668 [03:03<1:38:57,  0.11it/s, v_num=5, train_loss_g_step=0.544]Epoch 0:   3%|▎         | 20/668 [03:03<1:38:57,  0.11it/s, v_num=5, train_loss_g_step=0.493]Epoch 0:   3%|▎         | 21/668 [03:57<2:01:47,  0.09it/s, v_num=5, train_loss_g_step=0.493]Epoch 0:   3%|▎         | 21/668 [03:57<2:01:47,  0.09it/s, v_num=5, train_loss_g_step=0.400]Epoch 0:   3%|▎         | 22/668 [04:43<2:18:53,  0.08it/s, v_num=5, train_loss_g_step=0.400]Epoch 0:   3%|▎         | 22/668 [04:43<2:18:53,  0.08it/s, v_num=5, train_loss_g_step=0.455]Epoch 0:   3%|▎         | 23/668 [04:47<2:14:32,  0.08it/s, v_num=5, train_loss_g_step=0.455]Epoch 0:   3%|▎         | 23/668 [04:47<2:14:32,  0.08it/s, v_num=5, train_loss_g_step=0.402]Epoch 0:   4%|▎         | 24/668 [04:51<2:10:33,  0.08it/s, v_num=5, train_loss_g_step=0.402]Epoch 0:   4%|▎         | 24/668 [04:51<2:10:33,  0.08it/s, v_num=5, train_loss_g_step=0.464]Epoch 0:   4%|▎         | 25/668 [04:55<2:06:51,  0.08it/s, v_num=5, train_loss_g_step=0.464]Epoch 0:   4%|▎         | 25/668 [04:55<2:06:51,  0.08it/s, v_num=5, train_loss_g_step=0.422]Epoch 0:   4%|▍         | 26/668 [05:00<2:03:36,  0.09it/s, v_num=5, train_loss_g_step=0.422]Epoch 0:   4%|▍         | 26/668 [05:00<2:03:36,  0.09it/s, v_num=5, train_loss_g_step=0.345]Epoch 0:   4%|▍         | 27/668 [05:05<2:00:42,  0.09it/s, v_num=5, train_loss_g_step=0.345]Epoch 0:   4%|▍         | 27/668 [05:05<2:00:42,  0.09it/s, v_num=5, train_loss_g_step=0.430]Epoch 0:   4%|▍         | 28/668 [05:09<1:57:54,  0.09it/s, v_num=5, train_loss_g_step=0.430]Epoch 0:   4%|▍         | 28/668 [05:09<1:57:54,  0.09it/s, v_num=5, train_loss_g_step=0.393]Epoch 0:   4%|▍         | 29/668 [05:14<1:55:23,  0.09it/s, v_num=5, train_loss_g_step=0.393]Epoch 0:   4%|▍         | 29/668 [05:14<1:55:23,  0.09it/s, v_num=5, train_loss_g_step=0.379]Epoch 0:   4%|▍         | 30/668 [05:18<1:53:02,  0.09it/s, v_num=5, train_loss_g_step=0.379]Epoch 0:   4%|▍         | 30/668 [05:18<1:53:02,  0.09it/s, v_num=5, train_loss_g_step=0.453]Epoch 0:   5%|▍         | 31/668 [05:23<1:50:48,  0.10it/s, v_num=5, train_loss_g_step=0.453]Epoch 0:   5%|▍         | 31/668 [05:23<1:50:48,  0.10it/s, v_num=5, train_loss_g_step=0.424]Epoch 0:   5%|▍         | 32/668 [05:28<1:48:45,  0.10it/s, v_num=5, train_loss_g_step=0.424]Epoch 0:   5%|▍         | 32/668 [05:28<1:48:45,  0.10it/s, v_num=5, train_loss_g_step=0.416]Epoch 0:   5%|▍         | 33/668 [05:33<1:46:59,  0.10it/s, v_num=5, train_loss_g_step=0.416]Epoch 0:   5%|▍         | 33/668 [05:33<1:46:59,  0.10it/s, v_num=5, train_loss_g_step=0.539]Epoch 0:   5%|▌         | 34/668 [05:38<1:45:15,  0.10it/s, v_num=5, train_loss_g_step=0.539]Epoch 0:   5%|▌         | 34/668 [05:38<1:45:15,  0.10it/s, v_num=5, train_loss_g_step=0.457]Epoch 0:   5%|▌         | 35/668 [05:42<1:43:18,  0.10it/s, v_num=5, train_loss_g_step=0.457]Epoch 0:   5%|▌         | 35/668 [05:42<1:43:18,  0.10it/s, v_num=5, train_loss_g_step=0.415]Epoch 0:   5%|▌         | 36/668 [05:46<1:41:27,  0.10it/s, v_num=5, train_loss_g_step=0.415]Epoch 0:   5%|▌         | 36/668 [05:46<1:41:27,  0.10it/s, v_num=5, train_loss_g_step=0.341]Epoch 0:   6%|▌         | 37/668 [05:50<1:39:42,  0.11it/s, v_num=5, train_loss_g_step=0.341]Epoch 0:   6%|▌         | 37/668 [05:50<1:39:42,  0.11it/s, v_num=5, train_loss_g_step=0.403]Epoch 0:   6%|▌         | 38/668 [05:54<1:38:03,  0.11it/s, v_num=5, train_loss_g_step=0.403]Epoch 0:   6%|▌         | 38/668 [05:54<1:38:03,  0.11it/s, v_num=5, train_loss_g_step=0.382]Epoch 0:   6%|▌         | 39/668 [05:58<1:36:28,  0.11it/s, v_num=5, train_loss_g_step=0.382]Epoch 0:   6%|▌         | 39/668 [05:58<1:36:28,  0.11it/s, v_num=5, train_loss_g_step=0.475]Epoch 0:   6%|▌         | 40/668 [06:02<1:34:58,  0.11it/s, v_num=5, train_loss_g_step=0.475]Epoch 0:   6%|▌         | 40/668 [06:02<1:34:58,  0.11it/s, v_num=5, train_loss_g_step=0.418]Epoch 0:   6%|▌         | 41/668 [06:07<1:33:35,  0.11it/s, v_num=5, train_loss_g_step=0.418]Epoch 0:   6%|▌         | 41/668 [06:07<1:33:35,  0.11it/s, v_num=5, train_loss_g_step=0.529]Epoch 0:   6%|▋         | 42/668 [06:11<1:32:20,  0.11it/s, v_num=5, train_loss_g_step=0.529]Epoch 0:   6%|▋         | 42/668 [06:11<1:32:20,  0.11it/s, v_num=5, train_loss_g_step=0.319]Epoch 0:   6%|▋         | 43/668 [06:16<1:31:12,  0.11it/s, v_num=5, train_loss_g_step=0.319]Epoch 0:   6%|▋         | 43/668 [06:16<1:31:12,  0.11it/s, v_num=5, train_loss_g_step=0.468]Epoch 0:   7%|▋         | 44/668 [06:21<1:30:05,  0.12it/s, v_num=5, train_loss_g_step=0.468]Epoch 0:   7%|▋         | 44/668 [06:21<1:30:05,  0.12it/s, v_num=5, train_loss_g_step=0.366]Epoch 0:   7%|▋         | 45/668 [06:25<1:29:00,  0.12it/s, v_num=5, train_loss_g_step=0.366]Epoch 0:   7%|▋         | 45/668 [06:25<1:29:00,  0.12it/s, v_num=5, train_loss_g_step=0.429]Epoch 0:   7%|▋         | 46/668 [06:31<1:28:08,  0.12it/s, v_num=5, train_loss_g_step=0.429]Epoch 0:   7%|▋         | 46/668 [06:31<1:28:08,  0.12it/s, v_num=5, train_loss_g_step=0.464]Epoch 0:   7%|▋         | 47/668 [06:38<1:27:40,  0.12it/s, v_num=5, train_loss_g_step=0.464]Epoch 0:   7%|▋         | 47/668 [06:38<1:27:40,  0.12it/s, v_num=5, train_loss_g_step=0.461]Epoch 0:   7%|▋         | 48/668 [06:47<1:27:46,  0.12it/s, v_num=5, train_loss_g_step=0.461]Epoch 0:   7%|▋         | 48/668 [06:47<1:27:46,  0.12it/s, v_num=5, train_loss_g_step=0.401]Epoch 0:   7%|▋         | 49/668 [06:51<1:26:44,  0.12it/s, v_num=5, train_loss_g_step=0.401]Epoch 0:   7%|▋         | 49/668 [06:51<1:26:44,  0.12it/s, v_num=5, train_loss_g_step=0.408]Epoch 0:   7%|▋         | 50/668 [06:56<1:25:51,  0.12it/s, v_num=5, train_loss_g_step=0.408]Epoch 0:   7%|▋         | 50/668 [06:56<1:25:51,  0.12it/s, v_num=5, train_loss_g_step=0.494]Epoch 0:   8%|▊         | 51/668 [07:01<1:25:01,  0.12it/s, v_num=5, train_loss_g_step=0.494]Epoch 0:   8%|▊         | 51/668 [07:01<1:25:01,  0.12it/s, v_num=5, train_loss_g_step=0.416]Epoch 0:   8%|▊         | 52/668 [07:06<1:24:06,  0.12it/s, v_num=5, train_loss_g_step=0.416]Epoch 0:   8%|▊         | 52/668 [07:06<1:24:06,  0.12it/s, v_num=5, train_loss_g_step=0.378]Epoch 0:   8%|▊         | 53/668 [07:12<1:23:43,  0.12it/s, v_num=5, train_loss_g_step=0.378]Epoch 0:   8%|▊         | 53/668 [07:12<1:23:43,  0.12it/s, v_num=5, train_loss_g_step=0.490]Epoch 0:   8%|▊         | 54/668 [07:21<1:23:41,  0.12it/s, v_num=5, train_loss_g_step=0.490]Epoch 0:   8%|▊         | 54/668 [07:21<1:23:41,  0.12it/s, v_num=5, train_loss_g_step=0.431]Epoch 0:   8%|▊         | 55/668 [07:28<1:23:20,  0.12it/s, v_num=5, train_loss_g_step=0.431]Epoch 0:   8%|▊         | 55/668 [07:28<1:23:20,  0.12it/s, v_num=5, train_loss_g_step=0.394]Epoch 0:   8%|▊         | 56/668 [07:33<1:22:40,  0.12it/s, v_num=5, train_loss_g_step=0.394]Epoch 0:   8%|▊         | 56/668 [07:33<1:22:40,  0.12it/s, v_num=5, train_loss_g_step=0.448]Epoch 0:   9%|▊         | 57/668 [07:38<1:21:57,  0.12it/s, v_num=5, train_loss_g_step=0.448]Epoch 0:   9%|▊         | 57/668 [07:38<1:21:57,  0.12it/s, v_num=5, train_loss_g_step=0.353]Epoch 0:   9%|▊         | 58/668 [07:43<1:21:19,  0.13it/s, v_num=5, train_loss_g_step=0.353]Epoch 0:   9%|▊         | 58/668 [07:43<1:21:19,  0.13it/s, v_num=5, train_loss_g_step=0.498]Epoch 0:   9%|▉         | 59/668 [07:49<1:20:41,  0.13it/s, v_num=5, train_loss_g_step=0.498]Epoch 0:   9%|▉         | 59/668 [07:49<1:20:41,  0.13it/s, v_num=5, train_loss_g_step=0.400]Epoch 0:   9%|▉         | 60/668 [08:20<1:24:30,  0.12it/s, v_num=5, train_loss_g_step=0.400]Epoch 0:   9%|▉         | 60/668 [08:20<1:24:31,  0.12it/s, v_num=5, train_loss_g_step=0.232]Epoch 0:   9%|▉         | 61/668 [08:28<1:24:20,  0.12it/s, v_num=5, train_loss_g_step=0.232]Epoch 0:   9%|▉         | 61/668 [08:28<1:24:20,  0.12it/s, v_num=5, train_loss_g_step=0.396]Epoch 0:   9%|▉         | 62/668 [08:33<1:23:38,  0.12it/s, v_num=5, train_loss_g_step=0.396]Epoch 0:   9%|▉         | 62/668 [08:33<1:23:38,  0.12it/s, v_num=5, train_loss_g_step=0.383]Epoch 0:   9%|▉         | 63/668 [08:38<1:22:59,  0.12it/s, v_num=5, train_loss_g_step=0.383]Epoch 0:   9%|▉         | 63/668 [08:38<1:22:59,  0.12it/s, v_num=5, train_loss_g_step=0.470]Epoch 0:  10%|▉         | 64/668 [08:43<1:22:16,  0.12it/s, v_num=5, train_loss_g_step=0.470]Epoch 0:  10%|▉         | 64/668 [08:43<1:22:16,  0.12it/s, v_num=5, train_loss_g_step=0.401]Epoch 0:  10%|▉         | 65/668 [08:48<1:21:38,  0.12it/s, v_num=5, train_loss_g_step=0.401]Epoch 0:  10%|▉         | 65/668 [08:48<1:21:38,  0.12it/s, v_num=5, train_loss_g_step=0.451]Epoch 0:  10%|▉         | 66/668 [08:52<1:20:53,  0.12it/s, v_num=5, train_loss_g_step=0.451]Epoch 0:  10%|▉         | 66/668 [08:52<1:20:53,  0.12it/s, v_num=5, train_loss_g_step=0.464]Epoch 0:  10%|█         | 67/668 [08:56<1:20:08,  0.12it/s, v_num=5, train_loss_g_step=0.464]Epoch 0:  10%|█         | 67/668 [08:56<1:20:08,  0.12it/s, v_num=5, train_loss_g_step=0.424]Epoch 0:  10%|█         | 68/668 [09:00<1:19:25,  0.13it/s, v_num=5, train_loss_g_step=0.424]Epoch 0:  10%|█         | 68/668 [09:00<1:19:25,  0.13it/s, v_num=5, train_loss_g_step=0.458]Epoch 0:  10%|█         | 69/668 [09:04<1:18:44,  0.13it/s, v_num=5, train_loss_g_step=0.458]Epoch 0:  10%|█         | 69/668 [09:04<1:18:44,  0.13it/s, v_num=5, train_loss_g_step=0.380]Epoch 0:  10%|█         | 70/668 [09:08<1:18:03,  0.13it/s, v_num=5, train_loss_g_step=0.380]Epoch 0:  10%|█         | 70/668 [09:08<1:18:03,  0.13it/s, v_num=5, train_loss_g_step=0.357]Epoch 0:  11%|█         | 71/668 [09:12<1:17:23,  0.13it/s, v_num=5, train_loss_g_step=0.357]Epoch 0:  11%|█         | 71/668 [09:12<1:17:23,  0.13it/s, v_num=5, train_loss_g_step=0.405]Epoch 0:  11%|█         | 72/668 [09:16<1:16:44,  0.13it/s, v_num=5, train_loss_g_step=0.405]Epoch 0:  11%|█         | 72/668 [09:16<1:16:44,  0.13it/s, v_num=5, train_loss_g_step=0.470]Epoch 0:  11%|█         | 73/668 [09:20<1:16:08,  0.13it/s, v_num=5, train_loss_g_step=0.470]Epoch 0:  11%|█         | 73/668 [09:20<1:16:08,  0.13it/s, v_num=5, train_loss_g_step=0.353]Epoch 0:  11%|█         | 74/668 [09:24<1:15:32,  0.13it/s, v_num=5, train_loss_g_step=0.353]Epoch 0:  11%|█         | 74/668 [09:24<1:15:32,  0.13it/s, v_num=5, train_loss_g_step=0.436]Epoch 0:  11%|█         | 75/668 [09:29<1:14:59,  0.13it/s, v_num=5, train_loss_g_step=0.436]Epoch 0:  11%|█         | 75/668 [09:29<1:14:59,  0.13it/s, v_num=5, train_loss_g_step=0.420]Epoch 0:  11%|█▏        | 76/668 [09:33<1:14:25,  0.13it/s, v_num=5, train_loss_g_step=0.420]Epoch 0:  11%|█▏        | 76/668 [09:33<1:14:25,  0.13it/s, v_num=5, train_loss_g_step=0.441]Epoch 0:  12%|█▏        | 77/668 [09:37<1:13:55,  0.13it/s, v_num=5, train_loss_g_step=0.441]Epoch 0:  12%|█▏        | 77/668 [09:37<1:13:55,  0.13it/s, v_num=5, train_loss_g_step=0.323]Epoch 0:  12%|█▏        | 78/668 [09:42<1:13:26,  0.13it/s, v_num=5, train_loss_g_step=0.323]Epoch 0:  12%|█▏        | 78/668 [09:42<1:13:26,  0.13it/s, v_num=5, train_loss_g_step=0.352]Epoch 0:  12%|█▏        | 79/668 [09:47<1:12:57,  0.13it/s, v_num=5, train_loss_g_step=0.352]Epoch 0:  12%|█▏        | 79/668 [09:47<1:12:57,  0.13it/s, v_num=5, train_loss_g_step=0.286]Epoch 0:  12%|█▏        | 80/668 [09:51<1:12:29,  0.14it/s, v_num=5, train_loss_g_step=0.286]Epoch 0:  12%|█▏        | 80/668 [09:51<1:12:29,  0.14it/s, v_num=5, train_loss_g_step=0.380]Epoch 0:  12%|█▏        | 81/668 [09:56<1:12:01,  0.14it/s, v_num=5, train_loss_g_step=0.380]Epoch 0:  12%|█▏        | 81/668 [09:56<1:12:01,  0.14it/s, v_num=5, train_loss_g_step=0.468]Epoch 0:  12%|█▏        | 82/668 [10:02<1:11:46,  0.14it/s, v_num=5, train_loss_g_step=0.468]Epoch 0:  12%|█▏        | 82/668 [10:02<1:11:46,  0.14it/s, v_num=5, train_loss_g_step=0.367]Epoch 0:  12%|█▏        | 83/668 [10:09<1:11:35,  0.14it/s, v_num=5, train_loss_g_step=0.367]Epoch 0:  12%|█▏        | 83/668 [10:09<1:11:35,  0.14it/s, v_num=5, train_loss_g_step=0.245]Epoch 0:  13%|█▎        | 84/668 [10:16<1:11:27,  0.14it/s, v_num=5, train_loss_g_step=0.245]Epoch 0:  13%|█▎        | 84/668 [10:16<1:11:27,  0.14it/s, v_num=5, train_loss_g_step=0.371]Epoch 0:  13%|█▎        | 85/668 [10:21<1:11:02,  0.14it/s, v_num=5, train_loss_g_step=0.371]Epoch 0:  13%|█▎        | 85/668 [10:21<1:11:02,  0.14it/s, v_num=5, train_loss_g_step=0.418]Epoch 0:  13%|█▎        | 86/668 [10:25<1:10:36,  0.14it/s, v_num=5, train_loss_g_step=0.418]Epoch 0:  13%|█▎        | 86/668 [10:25<1:10:36,  0.14it/s, v_num=5, train_loss_g_step=0.432]Epoch 0:  13%|█▎        | 87/668 [10:31<1:10:16,  0.14it/s, v_num=5, train_loss_g_step=0.432]Epoch 0:  13%|█▎        | 87/668 [10:31<1:10:16,  0.14it/s, v_num=5, train_loss_g_step=0.341]Epoch 0:  13%|█▎        | 88/668 [10:35<1:09:50,  0.14it/s, v_num=5, train_loss_g_step=0.341]Epoch 0:  13%|█▎        | 88/668 [10:35<1:09:50,  0.14it/s, v_num=5, train_loss_g_step=0.360]Epoch 0:  13%|█▎        | 89/668 [10:40<1:09:25,  0.14it/s, v_num=5, train_loss_g_step=0.360]Epoch 0:  13%|█▎        | 89/668 [10:40<1:09:25,  0.14it/s, v_num=5, train_loss_g_step=0.495]Epoch 0:  13%|█▎        | 90/668 [10:45<1:09:04,  0.14it/s, v_num=5, train_loss_g_step=0.495]Epoch 0:  13%|█▎        | 90/668 [10:45<1:09:04,  0.14it/s, v_num=5, train_loss_g_step=0.245]Epoch 0:  14%|█▎        | 91/668 [10:50<1:08:41,  0.14it/s, v_num=5, train_loss_g_step=0.245]Epoch 0:  14%|█▎        | 91/668 [10:50<1:08:41,  0.14it/s, v_num=5, train_loss_g_step=0.447]Epoch 0:  14%|█▍        | 92/668 [10:55<1:08:21,  0.14it/s, v_num=5, train_loss_g_step=0.447]Epoch 0:  14%|█▍        | 92/668 [10:55<1:08:21,  0.14it/s, v_num=5, train_loss_g_step=0.448]Epoch 0:  14%|█▍        | 93/668 [11:00<1:08:01,  0.14it/s, v_num=5, train_loss_g_step=0.448]Epoch 0:  14%|█▍        | 93/668 [11:00<1:08:01,  0.14it/s, v_num=5, train_loss_g_step=0.427]Epoch 0:  14%|█▍        | 94/668 [11:04<1:07:39,  0.14it/s, v_num=5, train_loss_g_step=0.427]Epoch 0:  14%|█▍        | 94/668 [11:04<1:07:39,  0.14it/s, v_num=5, train_loss_g_step=0.452]Epoch 0:  14%|█▍        | 95/668 [11:09<1:07:18,  0.14it/s, v_num=5, train_loss_g_step=0.452]Epoch 0:  14%|█▍        | 95/668 [11:09<1:07:18,  0.14it/s, v_num=5, train_loss_g_step=0.498]Epoch 0:  14%|█▍        | 96/668 [11:14<1:06:58,  0.14it/s, v_num=5, train_loss_g_step=0.498]Epoch 0:  14%|█▍        | 96/668 [11:14<1:06:58,  0.14it/s, v_num=5, train_loss_g_step=0.389]Epoch 0:  15%|█▍        | 97/668 [11:38<1:08:34,  0.14it/s, v_num=5, train_loss_g_step=0.389]Epoch 0:  15%|█▍        | 97/668 [11:38<1:08:34,  0.14it/s, v_num=5, train_loss_g_step=0.396]Epoch 0:  15%|█▍        | 98/668 [11:42<1:08:08,  0.14it/s, v_num=5, train_loss_g_step=0.396]Epoch 0:  15%|█▍        | 98/668 [11:42<1:08:08,  0.14it/s, v_num=5, train_loss_g_step=0.427]Epoch 0:  15%|█▍        | 99/668 [11:47<1:07:43,  0.14it/s, v_num=5, train_loss_g_step=0.427]Epoch 0:  15%|█▍        | 99/668 [11:47<1:07:43,  0.14it/s, v_num=5, train_loss_g_step=0.294]Epoch 0:  15%|█▍        | 100/668 [11:51<1:07:20,  0.14it/s, v_num=5, train_loss_g_step=0.294]Epoch 0:  15%|█▍        | 100/668 [11:51<1:07:20,  0.14it/s, v_num=5, train_loss_g_step=0.457]Epoch 0:  15%|█▌        | 101/668 [11:56<1:07:00,  0.14it/s, v_num=5, train_loss_g_step=0.457]Epoch 0:  15%|█▌        | 101/668 [11:56<1:07:00,  0.14it/s, v_num=5, train_loss_g_step=0.260]Epoch 0:  15%|█▌        | 102/668 [12:01<1:06:41,  0.14it/s, v_num=5, train_loss_g_step=0.260]Epoch 0:  15%|█▌        | 102/668 [12:01<1:06:41,  0.14it/s, v_num=5, train_loss_g_step=0.432]Epoch 0:  15%|█▌        | 103/668 [12:05<1:06:20,  0.14it/s, v_num=5, train_loss_g_step=0.432]Epoch 0:  15%|█▌        | 103/668 [12:05<1:06:20,  0.14it/s, v_num=5, train_loss_g_step=0.477]Epoch 0:  16%|█▌        | 104/668 [12:10<1:06:01,  0.14it/s, v_num=5, train_loss_g_step=0.477]Epoch 0:  16%|█▌        | 104/668 [12:10<1:06:01,  0.14it/s, v_num=5, train_loss_g_step=0.356]Epoch 0:  16%|█▌        | 105/668 [12:15<1:05:43,  0.14it/s, v_num=5, train_loss_g_step=0.356]Epoch 0:  16%|█▌        | 105/668 [12:15<1:05:43,  0.14it/s, v_num=5, train_loss_g_step=0.262]Epoch 0:  16%|█▌        | 106/668 [12:20<1:05:26,  0.14it/s, v_num=5, train_loss_g_step=0.262]Epoch 0:  16%|█▌        | 106/668 [12:20<1:05:26,  0.14it/s, v_num=5, train_loss_g_step=0.275]Epoch 0:  16%|█▌        | 107/668 [12:25<1:05:10,  0.14it/s, v_num=5, train_loss_g_step=0.275]Epoch 0:  16%|█▌        | 107/668 [12:25<1:05:10,  0.14it/s, v_num=5, train_loss_g_step=0.331]Epoch 0:  16%|█▌        | 108/668 [12:31<1:04:56,  0.14it/s, v_num=5, train_loss_g_step=0.331]Epoch 0:  16%|█▌        | 108/668 [12:31<1:04:56,  0.14it/s, v_num=5, train_loss_g_step=0.294]Epoch 0:  16%|█▋        | 109/668 [12:35<1:04:34,  0.14it/s, v_num=5, train_loss_g_step=0.294]Epoch 0:  16%|█▋        | 109/668 [12:35<1:04:34,  0.14it/s, v_num=5, train_loss_g_step=0.320]Epoch 0:  16%|█▋        | 110/668 [12:39<1:04:12,  0.14it/s, v_num=5, train_loss_g_step=0.320]Epoch 0:  16%|█▋        | 110/668 [12:39<1:04:12,  0.14it/s, v_num=5, train_loss_g_step=0.457]Epoch 0:  17%|█▋        | 111/668 [12:43<1:03:51,  0.15it/s, v_num=5, train_loss_g_step=0.457]Epoch 0:  17%|█▋        | 111/668 [12:43<1:03:51,  0.15it/s, v_num=5, train_loss_g_step=0.402]Epoch 0:  17%|█▋        | 112/668 [12:47<1:03:30,  0.15it/s, v_num=5, train_loss_g_step=0.402]Epoch 0:  17%|█▋        | 112/668 [12:47<1:03:30,  0.15it/s, v_num=5, train_loss_g_step=0.322]Epoch 0:  17%|█▋        | 113/668 [12:51<1:03:09,  0.15it/s, v_num=5, train_loss_g_step=0.322]Epoch 0:  17%|█▋        | 113/668 [12:51<1:03:09,  0.15it/s, v_num=5, train_loss_g_step=0.296]Epoch 0:  17%|█▋        | 114/668 [12:55<1:02:49,  0.15it/s, v_num=5, train_loss_g_step=0.296]Epoch 0:  17%|█▋        | 114/668 [12:55<1:02:49,  0.15it/s, v_num=5, train_loss_g_step=0.336]Epoch 0:  17%|█▋        | 115/668 [12:59<1:02:28,  0.15it/s, v_num=5, train_loss_g_step=0.336]Epoch 0:  17%|█▋        | 115/668 [12:59<1:02:28,  0.15it/s, v_num=5, train_loss_g_step=0.368]