nohup: ignoring input
--------------------------------------------------------
ðŸš€ [A800] å¼€å§‹è®­ç»ƒ Met Mamba åŸºåº§æ¨¡åž‹ (BF16 Mixed)...
--------------------------------------------------------
Seed set to 42
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/3
[rank: 1] Seed set to 42
[rank: 2] Seed set to 42
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/3
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/3
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 3 processes
----------------------------------------------------------------------------------------------------

NCCL version 2.27.3+cuda12.9
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
[2025-11-30 02:04:00.802] [INFO] Loading configuration from file: /home/yyj/code/metai/config.yaml
[2025-11-30 02:04:00.852] [INFO] Dataset split: Train=4158, Val=519, Test=521
Param groups = {
  "decay": {
    "weight_decay": 0.05,
    "params": [
      "enc.stem.0.weight",
      "enc.enc.0.conv.conv.weight",
      "enc.enc.1.conv.conv.weight",
      "enc.enc.2.conv.conv.weight",
      "enc.enc.3.conv.conv.weight",
      "evolution.proj_in.weight",
      "evolution.proj_out.weight",
      "evolution.layers.0.scan_h.A_log",
      "evolution.layers.0.scan_h.in_proj.weight",
      "evolution.layers.0.scan_h.conv1d.weight",
      "evolution.layers.0.scan_h.x_proj.weight",
      "evolution.layers.0.scan_h.dt_proj.weight",
      "evolution.layers.0.scan_h.out_proj.weight",
      "evolution.layers.0.scan_v.A_log",
      "evolution.layers.0.scan_v.in_proj.weight",
      "evolution.layers.0.scan_v.conv1d.weight",
      "evolution.layers.0.scan_v.x_proj.weight",
      "evolution.layers.0.scan_v.dt_proj.weight",
      "evolution.layers.0.scan_v.out_proj.weight",
      "evolution.layers.0.fusion_gate.gate_net.0.weight",
      "evolution.layers.0.fusion_gate.gate_net.2.weight",
      "evolution.layers.0.mlp.fc1.weight",
      "evolution.layers.0.mlp.dwconv.weight",
      "evolution.layers.0.mlp.fc2.weight",
      "evolution.layers.1.scan_t.A_log",
      "evolution.layers.1.scan_t.in_proj.weight",
      "evolution.layers.1.scan_t.conv1d.weight",
      "evolution.layers.1.scan_t.x_proj.weight",
      "evolution.layers.1.scan_t.dt_proj.weight",
      "evolution.layers.1.scan_t.out_proj.weight",
      "evolution.layers.1.mlp.fc1.weight",
      "evolution.layers.1.mlp.dwconv.weight",
      "evolution.layers.1.mlp.fc2.weight",
      "evolution.layers.2.scan_h.A_log",
      "evolution.layers.2.scan_h.in_proj.weight",
      "evolution.layers.2.scan_h.conv1d.weight",
      "evolution.layers.2.scan_h.x_proj.weight",
      "evolution.layers.2.scan_h.dt_proj.weight",
      "evolution.layers.2.scan_h.out_proj.weight",
      "evolution.layers.2.scan_v.A_log",
      "evolution.layers.2.scan_v.in_proj.weight",
      "evolution.layers.2.scan_v.conv1d.weight",
      "evolution.layers.2.scan_v.x_proj.weight",
      "evolution.layers.2.scan_v.dt_proj.weight",
      "evolution.layers.2.scan_v.out_proj.weight",
      "evolution.layers.2.fusion_gate.gate_net.0.weight",
      "evolution.layers.2.fusion_gate.gate_net.2.weight",
      "evolution.layers.2.mlp.fc1.weight",
      "evolution.layers.2.mlp.dwconv.weight",
      "evolution.layers.2.mlp.fc2.weight",
      "evolution.layers.3.scan_t.A_log",
      "evolution.layers.3.scan_t.in_proj.weight",
      "evolution.layers.3.scan_t.conv1d.weight",
      "evolution.layers.3.scan_t.x_proj.weight",
      "evolution.layers.3.scan_t.dt_proj.weight",
      "evolution.layers.3.scan_t.out_proj.weight",
      "evolution.layers.3.mlp.fc1.weight",
      "evolution.layers.3.mlp.dwconv.weight",
      "evolution.layers.3.mlp.fc2.weight",
      "evolution.layers.4.scan_h.A_log",
      "evolution.layers.4.scan_h.in_proj.weight",
      "evolution.layers.4.scan_h.conv1d.weight",
      "evolution.layers.4.scan_h.x_proj.weight",
      "evolution.layers.4.scan_h.dt_proj.weight",
      "evolution.layers.4.scan_h.out_proj.weight",
      "evolution.layers.4.scan_v.A_log",
      "evolution.layers.4.scan_v.in_proj.weight",
      "evolution.layers.4.scan_v.conv1d.weight",
      "evolution.layers.4.scan_v.x_proj.weight",
      "evolution.layers.4.scan_v.dt_proj.weight",
      "evolution.layers.4.scan_v.out_proj.weight",
      "evolution.layers.4.fusion_gate.gate_net.0.weight",
      "evolution.layers.4.fusion_gate.gate_net.2.weight",
      "evolution.layers.4.mlp.fc1.weight",
      "evolution.layers.4.mlp.dwconv.weight",
      "evolution.layers.4.mlp.fc2.weight",
      "evolution.layers.5.scan_t.A_log",
      "evolution.layers.5.scan_t.in_proj.weight",
      "evolution.layers.5.scan_t.conv1d.weight",
      "evolution.layers.5.scan_t.x_proj.weight",
      "evolution.layers.5.scan_t.dt_proj.weight",
      "evolution.layers.5.scan_t.out_proj.weight",
      "evolution.layers.5.mlp.fc1.weight",
      "evolution.layers.5.mlp.dwconv.weight",
      "evolution.layers.5.mlp.fc2.weight",
      "latent_time_proj.0.weight",
      "latent_time_proj.1.weight",
      "dec.dec.0.conv.conv.0.weight",
      "dec.dec.1.conv.conv.weight",
      "dec.dec.2.conv.conv.0.weight",
      "dec.dec.3.conv.conv.weight",
      "dec.readout.weight",
      "skip_proj.time_proj.weight"
    ],
    "lr_scale": 1.0
  },
  "no_decay": {
    "weight_decay": 0.0,
    "params": [
      "enc.stem.1.weight",
      "enc.stem.1.bias",
      "enc.enc.0.conv.conv.bias",
      "enc.enc.0.conv.norm.weight",
      "enc.enc.0.conv.norm.bias",
      "enc.enc.1.conv.conv.bias",
      "enc.enc.1.conv.norm.weight",
      "enc.enc.1.conv.norm.bias",
      "enc.enc.2.conv.conv.bias",
      "enc.enc.2.conv.norm.weight",
      "enc.enc.2.conv.norm.bias",
      "enc.enc.3.conv.conv.bias",
      "enc.enc.3.conv.norm.weight",
      "enc.enc.3.conv.norm.bias",
      "evolution.proj_in.bias",
      "evolution.proj_out.bias",
      "evolution.layers.0.norm1.weight",
      "evolution.layers.0.norm1.bias",
      "evolution.layers.0.scan_h.D",
      "evolution.layers.0.scan_h.conv1d.bias",
      "evolution.layers.0.scan_h.dt_proj.bias",
      "evolution.layers.0.scan_v.D",
      "evolution.layers.0.scan_v.conv1d.bias",
      "evolution.layers.0.scan_v.dt_proj.bias",
      "evolution.layers.0.fusion_gate.gate_net.0.bias",
      "evolution.layers.0.fusion_gate.gate_net.2.bias",
      "evolution.layers.0.norm2.weight",
      "evolution.layers.0.norm2.bias",
      "evolution.layers.0.mlp.fc1.bias",
      "evolution.layers.0.mlp.dwconv.bias",
      "evolution.layers.0.mlp.fc2.bias",
      "evolution.layers.1.norm1.weight",
      "evolution.layers.1.norm1.bias",
      "evolution.layers.1.scan_t.D",
      "evolution.layers.1.scan_t.conv1d.bias",
      "evolution.layers.1.scan_t.dt_proj.bias",
      "evolution.layers.1.norm2.weight",
      "evolution.layers.1.norm2.bias",
      "evolution.layers.1.mlp.fc1.bias",
      "evolution.layers.1.mlp.dwconv.bias",
      "evolution.layers.1.mlp.fc2.bias",
      "evolution.layers.2.norm1.weight",
      "evolution.layers.2.norm1.bias",
      "evolution.layers.2.scan_h.D",
      "evolution.layers.2.scan_h.conv1d.bias",
      "evolution.layers.2.scan_h.dt_proj.bias",
      "evolution.layers.2.scan_v.D",
      "evolution.layers.2.scan_v.conv1d.bias",
      "evolution.layers.2.scan_v.dt_proj.bias",
      "evolution.layers.2.fusion_gate.gate_net.0.bias",
      "evolution.layers.2.fusion_gate.gate_net.2.bias",
      "evolution.layers.2.norm2.weight",
      "evolution.layers.2.norm2.bias",
      "evolution.layers.2.mlp.fc1.bias",
      "evolution.layers.2.mlp.dwconv.bias",
      "evolution.layers.2.mlp.fc2.bias",
      "evolution.layers.3.norm1.weight",
      "evolution.layers.3.norm1.bias",
      "evolution.layers.3.scan_t.D",
      "evolution.layers.3.scan_t.conv1d.bias",
      "evolution.layers.3.scan_t.dt_proj.bias",
      "evolution.layers.3.norm2.weight",
      "evolution.layers.3.norm2.bias",
      "evolution.layers.3.mlp.fc1.bias",
      "evolution.layers.3.mlp.dwconv.bias",
      "evolution.layers.3.mlp.fc2.bias",
      "evolution.layers.4.norm1.weight",
      "evolution.layers.4.norm1.bias",
      "evolution.layers.4.scan_h.D",
      "evolution.layers.4.scan_h.conv1d.bias",
      "evolution.layers.4.scan_h.dt_proj.bias",
      "evolution.layers.4.scan_v.D",
      "evolution.layers.4.scan_v.conv1d.bias",
      "evolution.layers.4.scan_v.dt_proj.bias",
      "evolution.layers.4.fusion_gate.gate_net.0.bias",
      "evolution.layers.4.fusion_gate.gate_net.2.bias",
      "evolution.layers.4.norm2.weight",
      "evolution.layers.4.norm2.bias",
      "evolution.layers.4.mlp.fc1.bias",
      "evolution.layers.4.mlp.dwconv.bias",
      "evolution.layers.4.mlp.fc2.bias",
      "evolution.layers.5.norm1.weight",
      "evolution.layers.5.norm1.bias",
      "evolution.layers.5.scan_t.D",
      "evolution.layers.5.scan_t.conv1d.bias",
      "evolution.layers.5.scan_t.dt_proj.bias",
      "evolution.layers.5.norm2.weight",
      "evolution.layers.5.norm2.bias",
      "evolution.layers.5.mlp.fc1.bias",
      "evolution.layers.5.mlp.dwconv.bias",
      "evolution.layers.5.mlp.fc2.bias",
      "latent_time_proj.0.bias",
      "latent_time_proj.1.bias",
      "dec.dec.0.conv.conv.0.bias",
      "dec.dec.0.conv.norm.weight",
      "dec.dec.0.conv.norm.bias",
      "dec.dec.1.conv.conv.bias",
      "dec.dec.1.conv.norm.weight",
      "dec.dec.1.conv.norm.bias",
      "dec.dec.2.conv.conv.0.bias",
      "dec.dec.2.conv.norm.weight",
      "dec.dec.2.conv.norm.bias",
      "dec.dec.3.conv.conv.bias",
      "dec.dec.3.conv.norm.weight",
      "dec.dec.3.conv.norm.bias",
      "dec.readout.bias",
      "skip_proj.time_proj.bias",
      "skip_proj.norm.weight",
      "skip_proj.norm.bias"
    ],
    "lr_scale": 1.0
  }
}[2025-11-30 02:03:59.522] [INFO] Loading configuration from file: /home/yyj/code/metai/config.yaml
[2025-11-30 02:03:59.573] [INFO] Dataset split: Train=4158, Val=519, Test=521
Param groups = {
  "decay": {
    "weight_decay": 0.05,
    "params": [
      "enc.stem.0.weight",
      "enc.enc.0.conv.conv.weight",
      "enc.enc.1.conv.conv.weight",
      "enc.enc.2.conv.conv.weight",
      "enc.enc.3.conv.conv.weight",
      "evolution.proj_in.weight",
      "evolution.proj_out.weight",
      "evolution.layers.0.scan_h.A_log",
      "evolution.layers.0.scan_h.in_proj.weight",
      "evolution.layers.0.scan_h.conv1d.weight",
      "evolution.layers.0.scan_h.x_proj.weight",
      "evolution.layers.0.scan_h.dt_proj.weight",
      "evolution.layers.0.scan_h.out_proj.weight",
      "evolution.layers.0.scan_v.A_log",
      "evolution.layers.0.scan_v.in_proj.weight",
      "evolution.layers.0.scan_v.conv1d.weight",
      "evolution.layers.0.scan_v.x_proj.weight",
      "evolution.layers.0.scan_v.dt_proj.weight",
      "evolution.layers.0.scan_v.out_proj.weight",
      "evolution.layers.0.fusion_gate.gate_net.0.weight",
      "evolution.layers.0.fusion_gate.gate_net.2.weight",
      "evolution.layers.0.mlp.fc1.weight",
      "evolution.layers.0.mlp.dwconv.weight",
      "evolution.layers.0.mlp.fc2.weight",
      "evolution.layers.1.scan_t.A_log",
      "evolution.layers.1.scan_t.in_proj.weight",
      "evolution.layers.1.scan_t.conv1d.weight",
      "evolution.layers.1.scan_t.x_proj.weight",
      "evolution.layers.1.scan_t.dt_proj.weight",
      "evolution.layers.1.scan_t.out_proj.weight",
      "evolution.layers.1.mlp.fc1.weight",
      "evolution.layers.1.mlp.dwconv.weight",
      "evolution.layers.1.mlp.fc2.weight",
      "evolution.layers.2.scan_h.A_log",
      "evolution.layers.2.scan_h.in_proj.weight",
      "evolution.layers.2.scan_h.conv1d.weight",
      "evolution.layers.2.scan_h.x_proj.weight",
      "evolution.layers.2.scan_h.dt_proj.weight",
      "evolution.layers.2.scan_h.out_proj.weight",
      "evolution.layers.2.scan_v.A_log",
      "evolution.layers.2.scan_v.in_proj.weight",
      "evolution.layers.2.scan_v.conv1d.weight",
      "evolution.layers.2.scan_v.x_proj.weight",
      "evolution.layers.2.scan_v.dt_proj.weight",
      "evolution.layers.2.scan_v.out_proj.weight",
      "evolution.layers.2.fusion_gate.gate_net.0.weight",
      "evolution.layers.2.fusion_gate.gate_net.2.weight",
      "evolution.layers.2.mlp.fc1.weight",
      "evolution.layers.2.mlp.dwconv.weight",
      "evolution.layers.2.mlp.fc2.weight",
      "evolution.layers.3.scan_t.A_log",
      "evolution.layers.3.scan_t.in_proj.weight",
      "evolution.layers.3.scan_t.conv1d.weight",
      "evolution.layers.3.scan_t.x_proj.weight",
      "evolution.layers.3.scan_t.dt_proj.weight",
      "evolution.layers.3.scan_t.out_proj.weight",
      "evolution.layers.3.mlp.fc1.weight",
      "evolution.layers.3.mlp.dwconv.weight",
      "evolution.layers.3.mlp.fc2.weight",
      "evolution.layers.4.scan_h.A_log",
      "evolution.layers.4.scan_h.in_proj.weight",
      "evolution.layers.4.scan_h.conv1d.weight",
      "evolution.layers.4.scan_h.x_proj.weight",
      "evolution.layers.4.scan_h.dt_proj.weight",
      "evolution.layers.4.scan_h.out_proj.weight",
      "evolution.layers.4.scan_v.A_log",
      "evolution.layers.4.scan_v.in_proj.weight",
      "evolution.layers.4.scan_v.conv1d.weight",
      "evolution.layers.4.scan_v.x_proj.weight",
      "evolution.layers.4.scan_v.dt_proj.weight",
      "evolution.layers.4.scan_v.out_proj.weight",
      "evolution.layers.4.fusion_gate.gate_net.0.weight",
      "evolution.layers.4.fusion_gate.gate_net.2.weight",
      "evolution.layers.4.mlp.fc1.weight",
      "evolution.layers.4.mlp.dwconv.weight",
      "evolution.layers.4.mlp.fc2.weight",
      "evolution.layers.5.scan_t.A_log",
      "evolution.layers.5.scan_t.in_proj.weight",
      "evolution.layers.5.scan_t.conv1d.weight",
      "evolution.layers.5.scan_t.x_proj.weight",
      "evolution.layers.5.scan_t.dt_proj.weight",
      "evolution.layers.5.scan_t.out_proj.weight",
      "evolution.layers.5.mlp.fc1.weight",
      "evolution.layers.5.mlp.dwconv.weight",
      "evolution.layers.5.mlp.fc2.weight",
      "latent_time_proj.0.weight",
      "latent_time_proj.1.weight",
      "dec.dec.0.conv.conv.0.weight",
      "dec.dec.1.conv.conv.weight",
      "dec.dec.2.conv.conv.0.weight",
      "dec.dec.3.conv.conv.weight",
      "dec.readout.weight",
      "skip_proj.time_proj.weight"
    ],
    "lr_scale": 1.0
  },
  "no_decay": {
    "weight_decay": 0.0,
    "params": [
      "enc.stem.1.weight",
      "enc.stem.1.bias",
      "enc.enc.0.conv.conv.bias",
      "enc.enc.0.conv.norm.weight",
      "enc.enc.0.conv.norm.bias",
      "enc.enc.1.conv.conv.bias",
      "enc.enc.1.conv.norm.weight",
      "enc.enc.1.conv.norm.bias",
      "enc.enc.2.conv.conv.bias",
      "enc.enc.2.conv.norm.weight",
      "enc.enc.2.conv.norm.bias",
      "enc.enc.3.conv.conv.bias",
      "enc.enc.3.conv.norm.weight",
      "enc.enc.3.conv.norm.bias",
      "evolution.proj_in.bias",
      "evolution.proj_out.bias",
      "evolution.layers.0.norm1.weight",
      "evolution.layers.0.norm1.bias",
      "evolution.layers.0.scan_h.D",
      "evolution.layers.0.scan_h.conv1d.bias",
      "evolution.layers.0.scan_h.dt_proj.bias",
      "evolution.layers.0.scan_v.D",
      "evolution.layers.0.scan_v.conv1d.bias",
      "evolution.layers.0.scan_v.dt_proj.bias",
      "evolution.layers.0.fusion_gate.gate_net.0.bias",
      "evolution.layers.0.fusion_gate.gate_net.2.bias",
      "evolution.layers.0.norm2.weight",
      "evolution.layers.0.norm2.bias",
      "evolution.layers.0.mlp.fc1.bias",
      "evolution.layers.0.mlp.dwconv.bias",
      "evolution.layers.0.mlp.fc2.bias",
      "evolution.layers.1.norm1.weight",
      "evolution.layers.1.norm1.bias",
      "evolution.layers.1.scan_t.D",
      "evolution.layers.1.scan_t.conv1d.bias",
      "evolution.layers.1.scan_t.dt_proj.bias",
      "evolution.layers.1.norm2.weight",
      "evolution.layers.1.norm2.bias",
      "evolution.layers.1.mlp.fc1.bias",
      "evolution.layers.1.mlp.dwconv.bias",
      "evolution.layers.1.mlp.fc2.bias",
      "evolution.layers.2.norm1.weight",
      "evolution.layers.2.norm1.bias",
      "evolution.layers.2.scan_h.D",
      "evolution.layers.2.scan_h.conv1d.bias",
      "evolution.layers.2.scan_h.dt_proj.bias",
      "evolution.layers.2.scan_v.D",
      "evolution.layers.2.scan_v.conv1d.bias",
      "evolution.layers.2.scan_v.dt_proj.bias",
      "evolution.layers.2.fusion_gate.gate_net.0.bias",
      "evolution.layers.2.fusion_gate.gate_net.2.bias",
      "evolution.layers.2.norm2.weight",
      "evolution.layers.2.norm2.bias",
      "evolution.layers.2.mlp.fc1.bias",
      "evolution.layers.2.mlp.dwconv.bias",
      "evolution.layers.2.mlp.fc2.bias",
      "evolution.layers.3.norm1.weight",
      "evolution.layers.3.norm1.bias",
      "evolution.layers.3.scan_t.D",
      "evolution.layers.3.scan_t.conv1d.bias",
      "evolution.layers.3.scan_t.dt_proj.bias",
      "evolution.layers.3.norm2.weight",
      "evolution.layers.3.norm2.bias",
      "evolution.layers.3.mlp.fc1.bias",
      "evolution.layers.3.mlp.dwconv.bias",
      "evolution.layers.3.mlp.fc2.bias",
      "evolution.layers.4.norm1.weight",
      "evolution.layers.4.norm1.bias",
      "evolution.layers.4.scan_h.D",
      "evolution.layers.4.scan_h.conv1d.bias",
      "evolution.layers.4.scan_h.dt_proj.bias",
      "evolution.layers.4.scan_v.D",
      "evolution.layers.4.scan_v.conv1d.bias",
      "evolution.layers.4.scan_v.dt_proj.bias",
      "evolution.layers.4.fusion_gate.gate_net.0.bias",
      "evolution.layers.4.fusion_gate.gate_net.2.bias",
      "evolution.layers.4.norm2.weight",
      "evolution.layers.4.norm2.bias",
      "evolution.layers.4.mlp.fc1.bias",
      "evolution.layers.4.mlp.dwconv.bias",
      "evolution.layers.4.mlp.fc2.bias",
      "evolution.layers.5.norm1.weight",
      "evolution.layers.5.norm1.bias",
      "evolution.layers.5.scan_t.D",
      "evolution.layers.5.scan_t.conv1d.bias",
      "evolution.layers.5.scan_t.dt_proj.bias",
      "evolution.layers.5.norm2.weight",
      "evolution.layers.5.norm2.bias",
      "evolution.layers.5.mlp.fc1.bias",
      "evolution.layers.5.mlp.dwconv.bias",
      "evolution.layers.5.mlp.fc2.bias",
      "latent_time_proj.0.bias",
      "latent_time_proj.1.bias",
      "dec.dec.0.conv.conv.0.bias",
      "dec.dec.0.conv.norm.weight",
      "dec.dec.0.conv.norm.bias",
      "dec.dec.1.conv.conv.bias",
      "dec.dec.1.conv.norm.weight",
      "dec.dec.1.conv.norm.bias",
      "dec.dec.2.conv.conv.0.bias",
      "dec.dec.2.conv.norm.weight",
      "dec.dec.2.conv.norm.bias",
      "dec.dec.3.conv.conv.bias",
      "dec.dec.3.conv.norm.weight",
      "dec.dec.3.conv.norm.bias",
      "dec.readout.bias",
      "skip_proj.time_proj.bias",
      "skip_proj.norm.weight",
      "skip_proj.norm.bias"
    ],
    "lr_scale": 1.0
  }
}[2025-11-30 02:03:59.521] [INFO] Loading configuration from file: /home/yyj/code/metai/config.yaml
[2025-11-30 02:03:59.572] [INFO] Dataset split: Train=4158, Val=519, Test=521
Param groups = {
  "decay": {
    "weight_decay": 0.05,
    "params": [
      "enc.stem.0.weight",
      "enc.enc.0.conv.conv.weight",
      "enc.enc.1.conv.conv.weight",
      "enc.enc.2.conv.conv.weight",
      "enc.enc.3.conv.conv.weight",
      "evolution.proj_in.weight",
      "evolution.proj_out.weight",
      "evolution.layers.0.scan_h.A_log",
      "evolution.layers.0.scan_h.in_proj.weight",
      "evolution.layers.0.scan_h.conv1d.weight",
      "evolution.layers.0.scan_h.x_proj.weight",
      "evolution.layers.0.scan_h.dt_proj.weight",
      "evolution.layers.0.scan_h.out_proj.weight",
      "evolution.layers.0.scan_v.A_log",
      "evolution.layers.0.scan_v.in_proj.weight",
      "evolution.layers.0.scan_v.conv1d.weight",
      "evolution.layers.0.scan_v.x_proj.weight",
      "evolution.layers.0.scan_v.dt_proj.weight",
      "evolution.layers.0.scan_v.out_proj.weight",
      "evolution.layers.0.fusion_gate.gate_net.0.weight",
      "evolution.layers.0.fusion_gate.gate_net.2.weight",
      "evolution.layers.0.mlp.fc1.weight",
      "evolution.layers.0.mlp.dwconv.weight",
      "evolution.layers.0.mlp.fc2.weight",
      "evolution.layers.1.scan_t.A_log",
      "evolution.layers.1.scan_t.in_proj.weight",
      "evolution.layers.1.scan_t.conv1d.weight",
      "evolution.layers.1.scan_t.x_proj.weight",
      "evolution.layers.1.scan_t.dt_proj.weight",
      "evolution.layers.1.scan_t.out_proj.weight",
      "evolution.layers.1.mlp.fc1.weight",
      "evolution.layers.1.mlp.dwconv.weight",
      "evolution.layers.1.mlp.fc2.weight",
      "evolution.layers.2.scan_h.A_log",
      "evolution.layers.2.scan_h.in_proj.weight",
      "evolution.layers.2.scan_h.conv1d.weight",
      "evolution.layers.2.scan_h.x_proj.weight",
      "evolution.layers.2.scan_h.dt_proj.weight",
      "evolution.layers.2.scan_h.out_proj.weight",
      "evolution.layers.2.scan_v.A_log",
      "evolution.layers.2.scan_v.in_proj.weight",
      "evolution.layers.2.scan_v.conv1d.weight",
      "evolution.layers.2.scan_v.x_proj.weight",
      "evolution.layers.2.scan_v.dt_proj.weight",
      "evolution.layers.2.scan_v.out_proj.weight",
      "evolution.layers.2.fusion_gate.gate_net.0.weight",
      "evolution.layers.2.fusion_gate.gate_net.2.weight",
      "evolution.layers.2.mlp.fc1.weight",
      "evolution.layers.2.mlp.dwconv.weight",
      "evolution.layers.2.mlp.fc2.weight",
      "evolution.layers.3.scan_t.A_log",
      "evolution.layers.3.scan_t.in_proj.weight",
      "evolution.layers.3.scan_t.conv1d.weight",
      "evolution.layers.3.scan_t.x_proj.weight",
      "evolution.layers.3.scan_t.dt_proj.weight",
      "evolution.layers.3.scan_t.out_proj.weight",
      "evolution.layers.3.mlp.fc1.weight",
      "evolution.layers.3.mlp.dwconv.weight",
      "evolution.layers.3.mlp.fc2.weight",
      "evolution.layers.4.scan_h.A_log",
      "evolution.layers.4.scan_h.in_proj.weight",
      "evolution.layers.4.scan_h.conv1d.weight",
      "evolution.layers.4.scan_h.x_proj.weight",
      "evolution.layers.4.scan_h.dt_proj.weight",
      "evolution.layers.4.scan_h.out_proj.weight",
      "evolution.layers.4.scan_v.A_log",
      "evolution.layers.4.scan_v.in_proj.weight",
      "evolution.layers.4.scan_v.conv1d.weight",
      "evolution.layers.4.scan_v.x_proj.weight",
      "evolution.layers.4.scan_v.dt_proj.weight",
      "evolution.layers.4.scan_v.out_proj.weight",
      "evolution.layers.4.fusion_gate.gate_net.0.weight",
      "evolution.layers.4.fusion_gate.gate_net.2.weight",
      "evolution.layers.4.mlp.fc1.weight",
      "evolution.layers.4.mlp.dwconv.weight",
      "evolution.layers.4.mlp.fc2.weight",
      "evolution.layers.5.scan_t.A_log",
      "evolution.layers.5.scan_t.in_proj.weight",
      "evolution.layers.5.scan_t.conv1d.weight",
      "evolution.layers.5.scan_t.x_proj.weight",
      "evolution.layers.5.scan_t.dt_proj.weight",
      "evolution.layers.5.scan_t.out_proj.weight",
      "evolution.layers.5.mlp.fc1.weight",
      "evolution.layers.5.mlp.dwconv.weight",
      "evolution.layers.5.mlp.fc2.weight",
      "latent_time_proj.0.weight",
      "latent_time_proj.1.weight",
      "dec.dec.0.conv.conv.0.weight",
      "dec.dec.1.conv.conv.weight",
      "dec.dec.2.conv.conv.0.weight",
      "dec.dec.3.conv.conv.weight",
      "dec.readout.weight",
      "skip_proj.time_proj.weight"
    ],
    "lr_scale": 1.0
  },
  "no_decay": {
    "weight_decay": 0.0,
    "params": [
      "enc.stem.1.weight",
      "enc.stem.1.bias",
      "enc.enc.0.conv.conv.bias",
      "enc.enc.0.conv.norm.weight",
      "enc.enc.0.conv.norm.bias",
      "enc.enc.1.conv.conv.bias",
      "enc.enc.1.conv.norm.weight",
      "enc.enc.1.conv.norm.bias",
      "enc.enc.2.conv.conv.bias",
      "enc.enc.2.conv.norm.weight",
      "enc.enc.2.conv.norm.bias",
      "enc.enc.3.conv.conv.bias",
      "enc.enc.3.conv.norm.weight",
      "enc.enc.3.conv.norm.bias",
      "evolution.proj_in.bias",
      "evolution.proj_out.bias",
      "evolution.layers.0.norm1.weight",
      "evolution.layers.0.norm1.bias",
      "evolution.layers.0.scan_h.D",
      "evolution.layers.0.scan_h.conv1d.bias",
      "evolution.layers.0.scan_h.dt_proj.bias",
      "evolution.layers.0.scan_v.D",
      "evolution.layers.0.scan_v.conv1d.bias",
      "evolution.layers.0.scan_v.dt_proj.bias",
      "evolution.layers.0.fusion_gate.gate_net.0.bias",
      "evolution.layers.0.fusion_gate.gate_net.2.bias",
      "evolution.layers.0.norm2.weight",
      "evolution.layers.0.norm2.bias",
      "evolution.layers.0.mlp.fc1.bias",
      "evolution.layers.0.mlp.dwconv.bias",
      "evolution.layers.0.mlp.fc2.bias",
      "evolution.layers.1.norm1.weight",
      "evolution.layers.1.norm1.bias",
      "evolution.layers.1.scan_t.D",
      "evolution.layers.1.scan_t.conv1d.bias",
      "evolution.layers.1.scan_t.dt_proj.bias",
      "evolution.layers.1.norm2.weight",
      "evolution.layers.1.norm2.bias",
      "evolution.layers.1.mlp.fc1.bias",
      "evolution.layers.1.mlp.dwconv.bias",
      "evolution.layers.1.mlp.fc2.bias",
      "evolution.layers.2.norm1.weight",
      "evolution.layers.2.norm1.bias",
      "evolution.layers.2.scan_h.D",
      "evolution.layers.2.scan_h.conv1d.bias",
      "evolution.layers.2.scan_h.dt_proj.bias",
      "evolution.layers.2.scan_v.D",
      "evolution.layers.2.scan_v.conv1d.bias",
      "evolution.layers.2.scan_v.dt_proj.bias",
      "evolution.layers.2.fusion_gate.gate_net.0.bias",
      "evolution.layers.2.fusion_gate.gate_net.2.bias",
      "evolution.layers.2.norm2.weight",
      "evolution.layers.2.norm2.bias",
      "evolution.layers.2.mlp.fc1.bias",
      "evolution.layers.2.mlp.dwconv.bias",
      "evolution.layers.2.mlp.fc2.bias",
      "evolution.layers.3.norm1.weight",
      "evolution.layers.3.norm1.bias",
      "evolution.layers.3.scan_t.D",
      "evolution.layers.3.scan_t.conv1d.bias",
      "evolution.layers.3.scan_t.dt_proj.bias",
      "evolution.layers.3.norm2.weight",
      "evolution.layers.3.norm2.bias",
      "evolution.layers.3.mlp.fc1.bias",
      "evolution.layers.3.mlp.dwconv.bias",
      "evolution.layers.3.mlp.fc2.bias",
      "evolution.layers.4.norm1.weight",
      "evolution.layers.4.norm1.bias",
      "evolution.layers.4.scan_h.D",
      "evolution.layers.4.scan_h.conv1d.bias",
      "evolution.layers.4.scan_h.dt_proj.bias",
      "evolution.layers.4.scan_v.D",
      "evolution.layers.4.scan_v.conv1d.bias",
      "evolution.layers.4.scan_v.dt_proj.bias",
      "evolution.layers.4.fusion_gate.gate_net.0.bias",
      "evolution.layers.4.fusion_gate.gate_net.2.bias",
      "evolution.layers.4.norm2.weight",
      "evolution.layers.4.norm2.bias",
      "evolution.layers.4.mlp.fc1.bias",
      "evolution.layers.4.mlp.dwconv.bias",
      "evolution.layers.4.mlp.fc2.bias",
      "evolution.layers.5.norm1.weight",
      "evolution.layers.5.norm1.bias",
      "evolution.layers.5.scan_t.D",
      "evolution.layers.5.scan_t.conv1d.bias",
      "evolution.layers.5.scan_t.dt_proj.bias",
      "evolution.layers.5.norm2.weight",
      "evolution.layers.5.norm2.bias",
      "evolution.layers.5.mlp.fc1.bias",
      "evolution.layers.5.mlp.dwconv.bias",
      "evolution.layers.5.mlp.fc2.bias",
      "latent_time_proj.0.bias",
      "latent_time_proj.1.bias",
      "dec.dec.0.conv.conv.0.bias",
      "dec.dec.0.conv.norm.weight",
      "dec.dec.0.conv.norm.bias",
      "dec.dec.1.conv.conv.bias",
      "dec.dec.1.conv.norm.weight",
      "dec.dec.1.conv.norm.bias",
      "dec.dec.2.conv.conv.0.bias",
      "dec.dec.2.conv.norm.weight",
      "dec.dec.2.conv.norm.bias",
      "dec.dec.3.conv.conv.bias",
      "dec.dec.3.conv.norm.weight",
      "dec.dec.3.conv.norm.bias",
      "dec.readout.bias",
      "skip_proj.time_proj.bias",
      "skip_proj.norm.weight",
      "skip_proj.norm.bias"
    ],
    "lr_scale": 1.0
  }
}/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/lightning/pytorch/utilities/model_summary/model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.

  | Name         | Type       | Params | Mode 
----------------------------------------------------
0 | model        | MeteoMamba | 7.8 M  | train
1 | criterion    | HybridLoss | 0      | train
2 | valid_scorer | MetScore   | 0      | train
----------------------------------------------------
7.8 M     Trainable params
0         Non-trainable params
7.8 M     Total params
31.324    Total estimated model params size (MB)
212       Modules in train mode
0         Modules in eval mode

Sanity Checking: |          | 0/? [00:00<?, ?it/s]

Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  0.14it/s]Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  0.23it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training: |          | 0/? [00:00<?, ?it/s]Epoch 0:   0%|          | 0/347 [00:00<?, ?it/s]Epoch 0:   0%|          | 1/347 [00:17<1:39:12,  0.06it/s]Epoch 0:   0%|          | 1/347 [00:17<1:39:13,  0.06it/s, v_num=1, train_loss_step=2.630]Epoch 0:   1%|          | 2/347 [00:19<56:40,  0.10it/s, v_num=1, train_loss_step=2.630]  Epoch 0:   1%|          | 2/347 [00:20<58:44,  0.10it/s, v_num=1, train_loss_step=2.530]Epoch 0:   1%|          | 3/347 [00:22<42:15,  0.14it/s, v_num=1, train_loss_step=2.530]Epoch 0:   1%|          | 3/347 [00:22<43:38,  0.13it/s, v_num=1, train_loss_step=2.510]/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/autograd/graph.py:829: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1024, 1, 3, 3], strides() = [9, 1, 3, 1]
bucket_view.sizes() = [1024, 1, 3, 3], strides() = [9, 9, 3, 1] (Triggered internally at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:334.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/autograd/graph.py:829: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1024, 1, 3, 3], strides() = [9, 1, 3, 1]
bucket_view.sizes() = [1024, 1, 3, 3], strides() = [9, 9, 3, 1] (Triggered internally at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:334.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/yyj/opt/anaconda3/envs/metai/lib/python3.11/site-packages/torch/autograd/graph.py:829: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [1024, 1, 3, 3], strides() = [9, 1, 3, 1]
bucket_view.sizes() = [1024, 1, 3, 3], strides() = [9, 9, 3, 1] (Triggered internally at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:334.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Epoch 0:   1%|          | 4/347 [00:24<35:20,  0.16it/s, v_num=1, train_loss_step=2.510]Epoch 0:   1%|          | 4/347 [00:24<35:20,  0.16it/s, v_num=1, train_loss_step=2.560]Epoch 0:   1%|â–         | 5/347 [00:25<29:17,  0.19it/s, v_num=1, train_loss_step=2.560]Epoch 0:   1%|â–         | 5/347 [00:26<30:06,  0.19it/s, v_num=1, train_loss_step=2.420]Epoch 0:   2%|â–         | 6/347 [00:27<25:55,  0.22it/s, v_num=1, train_loss_step=2.420]Epoch 0:   2%|â–         | 6/347 [00:28<26:36,  0.21it/s, v_num=1, train_loss_step=2.330]Epoch 0:   2%|â–         | 7/347 [00:29<23:29,  0.24it/s, v_num=1, train_loss_step=2.330]Epoch 0:   2%|â–         | 7/347 [00:29<24:05,  0.24it/s, v_num=1, train_loss_step=2.310]Epoch 0:   2%|â–         | 8/347 [00:30<21:53,  0.26it/s, v_num=1, train_loss_step=2.310]Epoch 0:   2%|â–         | 8/347 [00:31<22:11,  0.25it/s, v_num=1, train_loss_step=2.320]Epoch 0:   3%|â–Ž         | 9/347 [00:32<20:27,  0.28it/s, v_num=1, train_loss_step=2.320]Epoch 0:   3%|â–Ž         | 9/347 [00:33<20:59,  0.27it/s, v_num=1, train_loss_step=2.150]Epoch 0:   3%|â–Ž         | 10/347 [00:34<19:26,  0.29it/s, v_num=1, train_loss_step=2.150]Epoch 0:   3%|â–Ž         | 10/347 [00:35<19:48,  0.28it/s, v_num=1, train_loss_step=2.090]Epoch 0:   3%|â–Ž         | 11/347 [00:36<18:48,  0.30it/s, v_num=1, train_loss_step=2.090]Epoch 0:   3%|â–Ž         | 11/347 [00:37<19:08,  0.29it/s, v_num=1, train_loss_step=2.190]Epoch 0:   3%|â–Ž         | 12/347 [00:39<18:08,  0.31it/s, v_num=1, train_loss_step=2.190]Epoch 0:   3%|â–Ž         | 12/347 [00:39<18:23,  0.30it/s, v_num=1, train_loss_step=2.220]Epoch 0:   4%|â–Ž         | 13/347 [00:40<17:22,  0.32it/s, v_num=1, train_loss_step=2.220]Epoch 0:   4%|â–Ž         | 13/347 [00:41<17:38,  0.32it/s, v_num=1, train_loss_step=2.070]Epoch 0:   4%|â–         | 14/347 [00:42<16:52,  0.33it/s, v_num=1, train_loss_step=2.070]Epoch 0:   4%|â–         | 14/347 [00:43<17:11,  0.32it/s, v_num=1, train_loss_step=1.910]Epoch 0:   4%|â–         | 15/347 [00:44<16:27,  0.34it/s, v_num=1, train_loss_step=1.910]Epoch 0:   4%|â–         | 15/347 [00:45<16:38,  0.33it/s, v_num=1, train_loss_step=2.050]Epoch 0:   5%|â–         | 16/347 [00:46<16:07,  0.34it/s, v_num=1, train_loss_step=2.050]Epoch 0:   5%|â–         | 16/347 [00:47<16:14,  0.34it/s, v_num=1, train_loss_step=1.890]Epoch 0:   5%|â–         | 17/347 [00:48<15:35,  0.35it/s, v_num=1, train_loss_step=1.890]Epoch 0:   5%|â–         | 17/347 [00:48<15:49,  0.35it/s, v_num=1, train_loss_step=2.010]Epoch 0:   5%|â–Œ         | 18/347 [00:50<15:17,  0.36it/s, v_num=1, train_loss_step=2.010]Epoch 0:   5%|â–Œ         | 18/347 [00:50<15:29,  0.35it/s, v_num=1, train_loss_step=1.890]Epoch 0:   5%|â–Œ         | 19/347 [00:52<15:06,  0.36it/s, v_num=1, train_loss_step=1.890]Epoch 0:   5%|â–Œ         | 19/347 [00:53<15:18,  0.36it/s, v_num=1, train_loss_step=1.970]Epoch 0:   6%|â–Œ         | 20/347 [00:54<14:55,  0.37it/s, v_num=1, train_loss_step=1.970]Epoch 0:   6%|â–Œ         | 20/347 [00:55<15:02,  0.36it/s, v_num=1, train_loss_step=1.960]Epoch 0:   6%|â–Œ         | 21/347 [00:56<14:31,  0.37it/s, v_num=1, train_loss_step=1.960]Epoch 0:   6%|â–Œ         | 21/347 [00:56<14:42,  0.37it/s, v_num=1, train_loss_step=1.840]Epoch 0:   6%|â–‹         | 22/347 [00:57<14:14,  0.38it/s, v_num=1, train_loss_step=1.840]Epoch 0:   6%|â–‹         | 22/347 [00:58<14:24,  0.38it/s, v_num=1, train_loss_step=2.010]Epoch 0:   7%|â–‹         | 23/347 [00:59<13:57,  0.39it/s, v_num=1, train_loss_step=2.010]Epoch 0:   7%|â–‹         | 23/347 [01:00<14:08,  0.38it/s, v_num=1, train_loss_step=1.820]Epoch 0:   7%|â–‹         | 24/347 [01:01<13:47,  0.39it/s, v_num=1, train_loss_step=1.820]Epoch 0:   7%|â–‹         | 24/347 [01:01<13:52,  0.39it/s, v_num=1, train_loss_step=1.930]Epoch 0:   7%|â–‹         | 25/347 [01:02<13:29,  0.40it/s, v_num=1, train_loss_step=1.930]Epoch 0:   7%|â–‹         | 25/347 [01:03<13:38,  0.39it/s, v_num=1, train_loss_step=1.870]Epoch 0:   7%|â–‹         | 26/347 [01:04<13:16,  0.40it/s, v_num=1, train_loss_step=1.870]Epoch 0:   7%|â–‹         | 26/347 [01:05<13:25,  0.40it/s, v_num=1, train_loss_step=2.040]Epoch 0:   8%|â–Š         | 27/347 [01:06<13:04,  0.41it/s, v_num=1, train_loss_step=2.040]Epoch 0:   8%|â–Š         | 27/347 [01:06<13:12,  0.40it/s, v_num=1, train_loss_step=1.960]Epoch 0:   8%|â–Š         | 28/347 [01:08<12:56,  0.41it/s, v_num=1, train_loss_step=1.960]Epoch 0:   8%|â–Š         | 28/347 [01:08<13:01,  0.41it/s, v_num=1, train_loss_step=1.930]Epoch 0:   8%|â–Š         | 29/347 [01:09<12:42,  0.42it/s, v_num=1, train_loss_step=1.930]Epoch 0:   8%|â–Š         | 29/347 [01:10<12:50,  0.41it/s, v_num=1, train_loss_step=1.780]Epoch 0:   9%|â–Š         | 30/347 [01:11<12:32,  0.42it/s, v_num=1, train_loss_step=1.780]Epoch 0:   9%|â–Š         | 30/347 [01:11<12:40,  0.42it/s, v_num=1, train_loss_step=1.920]Epoch 0:   9%|â–‰         | 31/347 [01:12<12:22,  0.43it/s, v_num=1, train_loss_step=1.920]Epoch 0:   9%|â–‰         | 31/347 [01:13<12:30,  0.42it/s, v_num=1, train_loss_step=1.950]Epoch 0:   9%|â–‰         | 32/347 [01:14<12:17,  0.43it/s, v_num=1, train_loss_step=1.950]Epoch 0:   9%|â–‰         | 32/347 [01:15<12:21,  0.42it/s, v_num=1, train_loss_step=2.030]Epoch 0:  10%|â–‰         | 33/347 [01:16<12:05,  0.43it/s, v_num=1, train_loss_step=2.030]Epoch 0:  10%|â–‰         | 33/347 [01:16<12:12,  0.43it/s, v_num=1, train_loss_step=1.780]Epoch 0:  10%|â–‰         | 34/347 [01:17<11:57,  0.44it/s, v_num=1, train_loss_step=1.780]Epoch 0:  10%|â–‰         | 34/347 [01:18<12:03,  0.43it/s, v_num=1, train_loss_step=1.790]Epoch 0:  10%|â–ˆ         | 35/347 [01:19<11:49,  0.44it/s, v_num=1, train_loss_step=1.790]Epoch 0:  10%|â–ˆ         | 35/347 [01:20<11:55,  0.44it/s, v_num=1, train_loss_step=1.740]Epoch 0:  10%|â–ˆ         | 36/347 [01:21<11:44,  0.44it/s, v_num=1, train_loss_step=1.740]Epoch 0:  10%|â–ˆ         | 36/347 [01:22<11:48,  0.44it/s, v_num=1, train_loss_step=1.750]Epoch 0:  11%|â–ˆ         | 37/347 [01:22<11:35,  0.45it/s, v_num=1, train_loss_step=1.750]Epoch 0:  11%|â–ˆ         | 37/347 [01:23<11:41,  0.44it/s, v_num=1, train_loss_step=1.810]Epoch 0:  11%|â–ˆ         | 38/347 [01:24<11:28,  0.45it/s, v_num=1, train_loss_step=1.810]Epoch 0:  11%|â–ˆ         | 38/347 [01:25<11:34,  0.45it/s, v_num=1, train_loss_step=1.830]Epoch 0:  11%|â–ˆ         | 39/347 [01:26<11:21,  0.45it/s, v_num=1, train_loss_step=1.830]Epoch 0:  11%|â–ˆ         | 39/347 [01:27<11:27,  0.45it/s, v_num=1, train_loss_step=1.750]Epoch 0:  12%|â–ˆâ–        | 40/347 [01:28<11:17,  0.45it/s, v_num=1, train_loss_step=1.750]Epoch 0:  12%|â–ˆâ–        | 40/347 [01:28<11:20,  0.45it/s, v_num=1, train_loss_step=1.830]Epoch 0:  12%|â–ˆâ–        | 41/347 [01:29<11:09,  0.46it/s, v_num=1, train_loss_step=1.830]Epoch 0:  12%|â–ˆâ–        | 41/347 [01:30<11:14,  0.45it/s, v_num=1, train_loss_step=1.920]Epoch 0:  12%|â–ˆâ–        | 42/347 [01:31<11:03,  0.46it/s, v_num=1, train_loss_step=1.920]Epoch 0:  12%|â–ˆâ–        | 42/347 [01:32<11:08,  0.46it/s, v_num=1, train_loss_step=1.950]Epoch 0:  12%|â–ˆâ–        | 43/347 [01:32<10:57,  0.46it/s, v_num=1, train_loss_step=1.950]Epoch 0:  12%|â–ˆâ–        | 43/347 [01:33<11:02,  0.46it/s, v_num=1, train_loss_step=1.870]Epoch 0:  13%|â–ˆâ–Ž        | 44/347 [01:34<10:54,  0.46it/s, v_num=1, train_loss_step=1.870]Epoch 0:  13%|â–ˆâ–Ž        | 44/347 [01:35<10:57,  0.46it/s, v_num=1, train_loss_step=1.830]Epoch 0:  13%|â–ˆâ–Ž        | 45/347 [01:36<10:48,  0.47it/s, v_num=1, train_loss_step=1.830]Epoch 0:  13%|â–ˆâ–Ž        | 45/347 [01:37<10:52,  0.46it/s, v_num=1, train_loss_step=1.800]Epoch 0:  13%|â–ˆâ–Ž        | 46/347 [01:38<10:43,  0.47it/s, v_num=1, train_loss_step=1.800]Epoch 0:  13%|â–ˆâ–Ž        | 46/347 [01:39<10:48,  0.46it/s, v_num=1, train_loss_step=1.850]Epoch 0:  14%|â–ˆâ–Ž        | 47/347 [01:40<10:39,  0.47it/s, v_num=1, train_loss_step=1.850]Epoch 0:  14%|â–ˆâ–Ž        | 47/347 [01:41<10:45,  0.46it/s, v_num=1, train_loss_step=1.810]Epoch 0:  14%|â–ˆâ–        | 48/347 [01:42<10:39,  0.47it/s, v_num=1, train_loss_step=1.810]Epoch 0:  14%|â–ˆâ–        | 48/347 [01:43<10:42,  0.47it/s, v_num=1, train_loss_step=1.820]Epoch 0:  14%|â–ˆâ–        | 49/347 [01:44<10:34,  0.47it/s, v_num=1, train_loss_step=1.820]Epoch 0:  14%|â–ˆâ–        | 49/347 [01:45<10:39,  0.47it/s, v_num=1, train_loss_step=1.790]Epoch 0:  14%|â–ˆâ–        | 50/347 [01:46<10:31,  0.47it/s, v_num=1, train_loss_step=1.790]Epoch 0:  14%|â–ˆâ–        | 50/347 [01:46<10:34,  0.47it/s, v_num=1, train_loss_step=1.830]Epoch 0:  15%|â–ˆâ–        | 51/347 [01:48<10:30,  0.47it/s, v_num=1, train_loss_step=1.830]Epoch 0:  15%|â–ˆâ–        | 51/347 [01:49<10:33,  0.47it/s, v_num=1, train_loss_step=1.810]Epoch 0:  15%|â–ˆâ–        | 52/347 [01:50<10:25,  0.47it/s, v_num=1, train_loss_step=1.810]Epoch 0:  15%|â–ˆâ–        | 52/347 [01:50<10:28,  0.47it/s, v_num=1, train_loss_step=1.870]Epoch 0:  15%|â–ˆâ–Œ        | 53/347 [01:51<10:19,  0.47it/s, v_num=1, train_loss_step=1.870]Epoch 0:  15%|â–ˆâ–Œ        | 53/347 [01:52<10:23,  0.47it/s, v_num=1, train_loss_step=1.780]Epoch 0:  16%|â–ˆâ–Œ        | 54/347 [01:53<10:15,  0.48it/s, v_num=1, train_loss_step=1.780]Epoch 0:  16%|â–ˆâ–Œ        | 54/347 [01:54<10:19,  0.47it/s, v_num=1, train_loss_step=1.870]Epoch 0:  16%|â–ˆâ–Œ        | 55/347 [01:55<10:10,  0.48it/s, v_num=1, train_loss_step=1.870]Epoch 0:  16%|â–ˆâ–Œ        | 55/347 [01:55<10:14,  0.48it/s, v_num=1, train_loss_step=1.900]Epoch 0:  16%|â–ˆâ–Œ        | 56/347 [01:57<10:08,  0.48it/s, v_num=1, train_loss_step=1.900]Epoch 0:  16%|â–ˆâ–Œ        | 56/347 [01:57<10:10,  0.48it/s, v_num=1, train_loss_step=1.790]Epoch 0:  16%|â–ˆâ–‹        | 57/347 [01:58<10:02,  0.48it/s, v_num=1, train_loss_step=1.790]Epoch 0:  16%|â–ˆâ–‹        | 57/347 [01:59<10:06,  0.48it/s, v_num=1, train_loss_step=1.910]Epoch 0:  17%|â–ˆâ–‹        | 58/347 [02:00<09:58,  0.48it/s, v_num=1, train_loss_step=1.910]Epoch 0:  17%|â–ˆâ–‹        | 58/347 [02:00<10:01,  0.48it/s, v_num=1, train_loss_step=1.870]Epoch 0:  17%|â–ˆâ–‹        | 59/347 [02:01<09:54,  0.48it/s, v_num=1, train_loss_step=1.870]Epoch 0:  17%|â–ˆâ–‹        | 59/347 [02:02<09:57,  0.48it/s, v_num=1, train_loss_step=1.900]Epoch 0:  17%|â–ˆâ–‹        | 60/347 [02:03<09:51,  0.48it/s, v_num=1, train_loss_step=1.900]Epoch 0:  17%|â–ˆâ–‹        | 60/347 [02:04<09:53,  0.48it/s, v_num=1, train_loss_step=1.840]Epoch 0:  18%|â–ˆâ–Š        | 61/347 [02:05<09:46,  0.49it/s, v_num=1, train_loss_step=1.840]Epoch 0:  18%|â–ˆâ–Š        | 61/347 [02:05<09:49,  0.48it/s, v_num=1, train_loss_step=1.790]Epoch 0:  18%|â–ˆâ–Š        | 62/347 [02:06<09:42,  0.49it/s, v_num=1, train_loss_step=1.790]Epoch 0:  18%|â–ˆâ–Š        | 62/347 [02:07<09:46,  0.49it/s, v_num=1, train_loss_step=1.770]Epoch 0:  18%|â–ˆâ–Š        | 63/347 [02:08<09:38,  0.49it/s, v_num=1, train_loss_step=1.770]Epoch 0:  18%|â–ˆâ–Š        | 63/347 [02:09<09:42,  0.49it/s, v_num=1, train_loss_step=1.770]Epoch 0:  18%|â–ˆâ–Š        | 64/347 [02:10<09:36,  0.49it/s, v_num=1, train_loss_step=1.770]Epoch 0:  18%|â–ˆâ–Š        | 64/347 [02:10<09:38,  0.49it/s, v_num=1, train_loss_step=1.820]Epoch 0:  19%|â–ˆâ–Š        | 65/347 [02:11<09:31,  0.49it/s, v_num=1, train_loss_step=1.820]Epoch 0:  19%|â–ˆâ–Š        | 65/347 [02:12<09:34,  0.49it/s, v_num=1, train_loss_step=1.840]Epoch 0:  19%|â–ˆâ–‰        | 66/347 [02:13<09:28,  0.49it/s, v_num=1, train_loss_step=1.840]Epoch 0:  19%|â–ˆâ–‰        | 66/347 [02:14<09:31,  0.49it/s, v_num=1, train_loss_step=1.670]Epoch 0:  19%|â–ˆâ–‰        | 67/347 [02:15<09:24,  0.50it/s, v_num=1, train_loss_step=1.670]Epoch 0:  19%|â–ˆâ–‰        | 67/347 [02:15<09:27,  0.49it/s, v_num=1, train_loss_step=1.710]Epoch 0:  20%|â–ˆâ–‰        | 68/347 [02:17<09:22,  0.50it/s, v_num=1, train_loss_step=1.710]Epoch 0:  20%|â–ˆâ–‰        | 68/347 [02:17<09:24,  0.49it/s, v_num=1, train_loss_step=1.740]Epoch 0:  20%|â–ˆâ–‰        | 69/347 [02:18<09:17,  0.50it/s, v_num=1, train_loss_step=1.740]Epoch 0:  20%|â–ˆâ–‰        | 69/347 [02:19<09:20,  0.50it/s, v_num=1, train_loss_step=1.820]Epoch 0:  20%|â–ˆâ–ˆ        | 70/347 [02:20<09:14,  0.50it/s, v_num=1, train_loss_step=1.820]Epoch 0:  20%|â–ˆâ–ˆ        | 70/347 [02:20<09:17,  0.50it/s, v_num=1, train_loss_step=1.890]Epoch 0:  20%|â–ˆâ–ˆ        | 71/347 [02:21<09:11,  0.50it/s, v_num=1, train_loss_step=1.890]Epoch 0:  20%|â–ˆâ–ˆ        | 71/347 [02:22<09:14,  0.50it/s, v_num=1, train_loss_step=1.970]Epoch 0:  21%|â–ˆâ–ˆ        | 72/347 [02:23<09:09,  0.50it/s, v_num=1, train_loss_step=1.970]Epoch 0:  21%|â–ˆâ–ˆ        | 72/347 [02:24<09:10,  0.50it/s, v_num=1, train_loss_step=1.830]Epoch 0:  21%|â–ˆâ–ˆ        | 73/347 [02:25<09:04,  0.50it/s, v_num=1, train_loss_step=1.830]Epoch 0:  21%|â–ˆâ–ˆ        | 73/347 [02:25<09:07,  0.50it/s, v_num=1, train_loss_step=1.920]Epoch 0:  21%|â–ˆâ–ˆâ–       | 74/347 [02:26<09:01,  0.50it/s, v_num=1, train_loss_step=1.920]Epoch 0:  21%|â–ˆâ–ˆâ–       | 74/347 [02:27<09:04,  0.50it/s, v_num=1, train_loss_step=1.760]Epoch 0:  22%|â–ˆâ–ˆâ–       | 75/347 [02:28<08:59,  0.50it/s, v_num=1, train_loss_step=1.760]Epoch 0:  22%|â–ˆâ–ˆâ–       | 75/347 [02:29<09:02,  0.50it/s, v_num=1, train_loss_step=1.860]Epoch 0:  22%|â–ˆâ–ˆâ–       | 76/347 [02:30<08:58,  0.50it/s, v_num=1, train_loss_step=1.860]Epoch 0:  22%|â–ˆâ–ˆâ–       | 76/347 [02:31<08:59,  0.50it/s, v_num=1, train_loss_step=1.850]Epoch 0:  22%|â–ˆâ–ˆâ–       | 77/347 [02:32<08:54,  0.50it/s, v_num=1, train_loss_step=1.850]Epoch 0:  22%|â–ˆâ–ˆâ–       | 77/347 [02:33<08:57,  0.50it/s, v_num=1, train_loss_step=1.770]Epoch 0:  22%|â–ˆâ–ˆâ–       | 78/347 [02:34<08:52,  0.51it/s, v_num=1, train_loss_step=1.770]Epoch 0:  22%|â–ˆâ–ˆâ–       | 78/347 [02:34<08:54,  0.50it/s, v_num=1, train_loss_step=1.810]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 79/347 [02:36<08:50,  0.51it/s, v_num=1, train_loss_step=1.810]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 79/347 [02:37<08:52,  0.50it/s, v_num=1, train_loss_step=1.820]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 80/347 [02:38<08:50,  0.50it/s, v_num=1, train_loss_step=1.820]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 80/347 [02:39<08:51,  0.50it/s, v_num=1, train_loss_step=1.750]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 81/347 [02:40<08:47,  0.50it/s, v_num=1, train_loss_step=1.750]Epoch 0:  23%|â–ˆâ–ˆâ–Ž       | 81/347 [02:41<08:49,  0.50it/s, v_num=1, train_loss_step=1.870]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 82/347 [02:42<08:43,  0.51it/s, v_num=1, train_loss_step=1.870]Epoch 0:  24%|â–ˆâ–ˆâ–Ž       | 82/347 [02:42<08:46,  0.50it/s, v_num=1, train_loss_step=1.840]Epoch 0:  24%|â–ˆâ–ˆâ–       | 83/347 [02:44<08:42,  0.51it/s, v_num=1, train_loss_step=1.840]Epoch 0:  24%|â–ˆâ–ˆâ–       | 83/347 [02:44<08:44,  0.50it/s, v_num=1, train_loss_step=1.850]Epoch 0:  24%|â–ˆâ–ˆâ–       | 84/347 [02:46<08:40,  0.51it/s, v_num=1, train_loss_step=1.850]Epoch 0:  24%|â–ˆâ–ˆâ–       | 84/347 [02:46<08:41,  0.50it/s, v_num=1, train_loss_step=1.840]Epoch 0:  24%|â–ˆâ–ˆâ–       | 85/347 [02:47<08:36,  0.51it/s, v_num=1, train_loss_step=1.840]Epoch 0:  24%|â–ˆâ–ˆâ–       | 85/347 [02:48<08:38,  0.51it/s, v_num=1, train_loss_step=1.790]Epoch 0:  25%|â–ˆâ–ˆâ–       | 86/347 [02:49<08:33,  0.51it/s, v_num=1, train_loss_step=1.790]Epoch 0:  25%|â–ˆâ–ˆâ–       | 86/347 [02:49<08:35,  0.51it/s, v_num=1, train_loss_step=1.870]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 87/347 [02:50<08:30,  0.51it/s, v_num=1, train_loss_step=1.870]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 87/347 [02:51<08:32,  0.51it/s, v_num=1, train_loss_step=1.900]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 88/347 [02:52<08:28,  0.51it/s, v_num=1, train_loss_step=1.900]Epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 88/347 [02:53<08:30,  0.51it/s, v_num=1, train_loss_step=1.830]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 89/347 [02:54<08:25,  0.51it/s, v_num=1, train_loss_step=1.830]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 89/347 [02:54<08:27,  0.51it/s, v_num=1, train_loss_step=1.750]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 90/347 [02:55<08:22,  0.51it/s, v_num=1, train_loss_step=1.750]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 90/347 [02:56<08:24,  0.51it/s, v_num=1, train_loss_step=1.850]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 91/347 [02:57<08:19,  0.51it/s, v_num=1, train_loss_step=1.850]Epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 91/347 [02:58<08:21,  0.51it/s, v_num=1, train_loss_step=1.950]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 92/347 [02:59<08:17,  0.51it/s, v_num=1, train_loss_step=1.950]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 92/347 [02:59<08:18,  0.51it/s, v_num=1, train_loss_step=1.880]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 93/347 [03:00<08:14,  0.51it/s, v_num=1, train_loss_step=1.880]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 93/347 [03:01<08:16,  0.51it/s, v_num=1, train_loss_step=1.930]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 94/347 [03:02<08:11,  0.51it/s, v_num=1, train_loss_step=1.930]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 94/347 [03:03<08:13,  0.51it/s, v_num=1, train_loss_step=1.720]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 95/347 [03:04<08:08,  0.52it/s, v_num=1, train_loss_step=1.720]Epoch 0:  27%|â–ˆâ–ˆâ–‹       | 95/347 [03:05<08:10,  0.51it/s, v_num=1, train_loss_step=1.880]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 96/347 [03:06<08:06,  0.52it/s, v_num=1, train_loss_step=1.880]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 96/347 [03:06<08:08,  0.51it/s, v_num=1, train_loss_step=1.720]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 97/347 [03:07<08:03,  0.52it/s, v_num=1, train_loss_step=1.720]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 97/347 [03:08<08:05,  0.52it/s, v_num=1, train_loss_step=1.820]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 98/347 [03:09<08:00,  0.52it/s, v_num=1, train_loss_step=1.820]Epoch 0:  28%|â–ˆâ–ˆâ–Š       | 98/347 [03:10<08:02,  0.52it/s, v_num=1, train_loss_step=1.880]Epoch 0:  29%|â–ˆâ–ˆâ–Š       | 99/347 [03:10<07:58,  0.52it/s, v_num=1, train_loss_step=1.880]