#!/bin/bash

# MeteoMamba å…¨æµç¨‹è„šæœ¬ (Optimized for 4x A800 80GB)
# åŒ…å«: Train (MeteoMamba) -> Test (MeteoMamba)
# Usage: bash run.scwds.mamba.sh [MODE]

# ================= ç¯å¢ƒå˜é‡ä¼˜åŒ– =================
export PYTHONPATH=$PYTHONPATH:$(pwd)
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
export NCCL_P2P_DISABLE=0
export NCCL_IB_DISABLE=0
export NCCL_DEBUG=WARN

# ================= å‚æ•°æ£€æŸ¥ =================
if [ $# -eq 0 ]; then
    echo "é”™è¯¯: è¯·æŒ‡å®šæ“ä½œæ¨¡å¼"
    echo "ç”¨æ³•: bash run.scwds.mamba.sh [MODE]"
    echo "æ”¯æŒçš„æ¨¡å¼:"
    echo " train      - è®­ç»ƒ MeteoMamba æ¨¡å‹"
    echo " test       - æµ‹è¯• MeteoMamba æ¨¡å‹"
    exit 1
fi

MODE=$1

# ================= é…ç½®å‚æ•° =================
DEVICES="[0,1,2,3]"
DATA_PATH="data/samples.jsonl"
SAVE_DIR="./output/meteo_mamba"

case $MODE in
    # ============================================================
    # 1. è®­ç»ƒ MeteoMamba (Stage 1)
    # ============================================================
    "train")
        echo "--------------------------------------------------------"
        echo "ğŸš€ [4x A800] å¼€å§‹è®­ç»ƒ MeteoMamba (Monitor: val_score)..."
        echo "--------------------------------------------------------"
        
        # [æ ¸å¿ƒä¿®æ”¹]
        # 1. æ·»åŠ  ModelCheckpoint: ç›‘æ§ val_score (max), ä¿å­˜ Top-3
        # 2. æ·»åŠ  EarlyStopping: ç›‘æ§ val_score (max), Patience=30
        # 3. æ˜¾å¼æŒ‡å®šå®Œæ•´ç±»åä»¥é€šè¿‡ CLI åŠ è½½
        
        python run/train_scwds_mamba.py fit \
            --seed_everything 42 \
            --trainer.default_root_dir $SAVE_DIR \
            --trainer.accelerator gpu \
            --trainer.devices $DEVICES \
            --trainer.strategy ddp \
            --trainer.precision bf16-mixed \
            --trainer.max_epochs 50 \
            --trainer.gradient_clip_val 0.5 \
            --trainer.accumulate_grad_batches 8 \
            --trainer.log_every_n_steps 10 \
            \
            --trainer.callbacks+=lightning.pytorch.callbacks.ModelCheckpoint \
            --trainer.callbacks.monitor "val_score" \
            --trainer.callbacks.mode "max" \
            --trainer.callbacks.save_top_k 3 \
            --trainer.callbacks.save_last true \
            --trainer.callbacks.filename "{epoch:02d}-{val_score:.4f}" \
            \
            --trainer.callbacks+=lightning.pytorch.callbacks.EarlyStopping \
            --trainer.callbacks.monitor "val_score" \
            --trainer.callbacks.mode "max" \
            --trainer.callbacks.patience 30 \
            --trainer.callbacks.min_delta 0.0 \
            \
            --model.in_shape "[10, 31, 256, 256]" \
            --model.aft_seq_length 20 \
            --model.hid_S 64 \
            --model.hid_T 256 \
            --model.N_S 4 \
            --model.N_T 8 \
            --model.lr 1e-3 \
            --model.min_lr 1e-5 \
            --model.warmup_epoch 10 \
            --model.use_curriculum_learning true \
            \
            --data.data_path $DATA_PATH \
            --data.batch_size 2 \
            --data.num_workers 16
        ;;
        
    # ============================================================
    # 2. æµ‹è¯• MeteoMamba
    # ============================================================
    "test")
        echo "----------------------------------------"
        echo "ğŸ§ª å¼€å§‹æµ‹è¯• MeteoMamba æ¨¡å‹..."
        echo "----------------------------------------"
        
        # è¿™é‡Œä¼˜å…ˆä½¿ç”¨ 'last.ckpt' ç»§ç»­è®­ç»ƒæˆ–æµ‹è¯•ï¼Œæˆ–è€…æ‰‹åŠ¨æŒ‡å®šæœ€ä½³æƒé‡
        CKPT_PATH=$(find $SAVE_DIR -name "*val_score*.ckpt" | sort -V | tail -n 1)
        
        if [ -z "$CKPT_PATH" ]; then
             CKPT_PATH=$(find $SAVE_DIR -name "last.ckpt" | head -n 1)
        fi
        
        if [ -z "$CKPT_PATH" ]; then
            echo "âŒ é”™è¯¯: æœªæ‰¾åˆ° Checkpoint æ–‡ä»¶ ($SAVE_DIR)"
            exit 1
        fi
        
        echo "Using Checkpoint: $CKPT_PATH"
        
        python run/train_scwds_mamba.py test \
            --trainer.accelerator gpu \
            --trainer.devices 1 \
            --trainer.precision bf16-mixed \
            --ckpt_path "$CKPT_PATH" \
            --data.data_path $DATA_PATH \
            --data.batch_size 1 \
            --data.num_workers 4
        ;;
        
    *)
        echo "é”™è¯¯: ä¸æ”¯æŒçš„æ“ä½œæ¨¡å¼ '$MODE'"
        echo "æ”¯æŒçš„æ¨¡å¼: train, test"
        exit 1
        ;;
esac

echo "âœ… æ“ä½œå®Œæˆï¼"