from typing import List, Optional, Union, Any
import torch
from torch import nn
import torch.nn.functional as F
import numpy as np

try:
    from torchmetrics.image import MultiScaleStructuralSimilarityIndexMeasure
    TORCHMETRICS_AVAILABLE = True
except ImportError:
    TORCHMETRICS_AVAILABLE = False
    MultiScaleStructuralSimilarityIndexMeasure = None
    # å ä½ç¬¦å‡½æ•° (ä¿æŒç®€æ´ï¼Œé˜²æ­¢å¯¼å…¥å¤±è´¥)
    def ssim_loss(pred, target): return F.mse_loss(pred, target)


def temporal_consistency_loss(pred: torch.Tensor) -> torch.Tensor:
    """
    è®¡ç®—æ—¶åºä¸€è‡´æ€§æŸå¤±ï¼ˆTemporal Consistency Lossï¼‰
    
    ç‰©ç†æ„ä¹‰ï¼š
    æƒ©ç½šé¢„æµ‹åºåˆ—ä¸­ç›¸é‚»æ—¶é—´æ­¥çš„å‰§çƒˆå˜åŒ–ï¼Œå‡å°‘æ—¶åºæŠ–åŠ¨ï¼ˆTemporal Flickeringï¼‰ï¼Œ
    æé«˜é¢„æµ‹çš„æ—¶åºå¹³æ»‘åº¦ã€‚
    
    Args:
        pred: é¢„æµ‹å€¼ï¼Œå½¢çŠ¶ä¸º [B, T, C, H, W] æˆ– [B, T, H, W]
    
    Returns:
        æ—¶åºä¸€è‡´æ€§æŸå¤±å€¼ï¼ˆæ ‡é‡ï¼‰
    """
    # å¤„ç†ä¸åŒçš„è¾“å…¥ç»´åº¦
    if len(pred.shape) == 5:
        # [B, T, C, H, W] -> [B, T, H, W] (å–ç¬¬ä¸€ä¸ªé€šé“æˆ–å¹³å‡)
        if pred.shape[2] == 1:
            pred = pred.squeeze(2)  # [B, T, H, W]
        else:
            pred = pred.mean(dim=2)  # [B, T, H, W]
    
    # å¦‚æœæ—¶é—´æ­¥æ•°å°äº2ï¼Œè¿”å›0
    if pred.shape[1] < 2:
        return torch.tensor(0.0, device=pred.device)
    
    # è®¡ç®—ç›¸é‚»æ—¶é—´æ­¥çš„å·®åˆ†
    pred_diff = pred[:, 1:] - pred[:, :-1]  # [B, T-1, H, W]
    
    # è®¡ç®—å·®åˆ†çš„L2èŒƒæ•°ï¼ˆé¼“åŠ±å¹³æ»‘å˜åŒ–ï¼‰
    temporal_loss = torch.mean(pred_diff ** 2)
    
    return temporal_loss

class EvolutionLoss(nn.Module):
    """
    [æ–°å¢] ç‰©ç†æ¼”å˜æŸå¤± (Physics-Guided Evolution Loss)
    
    ç†è®ºä¾æ®: 
    åŸºäºé›·è¾¾å›æ³¢çš„å¹³æµæ–¹ç¨‹ (Advection Equation) è¿‘ä¼¼: dI/dt + v * grad(I) = 0ã€‚
    å¦‚æœæ¨¡å‹çš„ä½ç½®é¢„æµ‹å‡ºç°åå·®ï¼Œä¼šå¯¼è‡´é¢„æµ‹åœºçš„æ—¶é—´å¯¼æ•° (dI/dt) ä¸çœŸå®åœºä¸ä¸€è‡´ã€‚
    é€šè¿‡æœ€å°åŒ–æ¼”å˜æ¢¯åº¦çš„è¯¯å·®ï¼Œæˆ‘ä»¬å¼•å…¥äº†éšå¼çš„è¿åŠ¨çº¦æŸï¼Œå¼ºè¿«æ¨¡å‹ä¿®æ­£ä½ç½®åå·®ã€‚
    """
    def __init__(self, weight=1.0):
        super().__init__()
        self.weight = weight
        self.l1 = nn.L1Loss(reduction='mean')

    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        """
        Args:
            pred: [B, T, H, W] (å·²å½’ä¸€åŒ– 0-1)
            target: [B, T, H, W]
        """
        # ç»´åº¦å…¼å®¹å¤„ç†
        if pred.dim() == 5: pred = pred.squeeze(2)
        if target.dim() == 5: target = target.squeeze(2)
            
        if pred.shape[1] < 2:
            return torch.tensor(0.0, device=pred.device)

        # è®¡ç®—ä¸€é˜¶æ—¶é—´å·®åˆ† (Finite Difference)
        # Pred å˜åŒ–é‡
        pred_diff = pred[:, 1:] - pred[:, :-1]
        # True å˜åŒ–é‡
        target_diff = target[:, 1:] - target[:, :-1]

        # æƒ©ç½šä¸¤è€…çš„å·®å¼‚
        loss = self.l1(pred_diff, target_diff)
        
        return self.weight * loss

def create_threshold_weights(target: torch.Tensor, 
                             thresholds: List[float],
                             weights: Optional[List[float]] = None) -> torch.Tensor:
    """[ä¼˜åŒ–ç‰ˆ] æ ¹æ®é™æ°´é˜ˆå€¼åˆ›å»ºæƒé‡å¼ é‡ï¼Œä½¿ç”¨ torch.bucketizeã€‚"""
    if weights is None:
        n_intervals = len(thresholds) + 1
        weights = [0.5 + i * 0.5 for i in range(n_intervals)]
    
    if len(weights) != len(thresholds) + 1:
        raise ValueError(f"æƒé‡æ•°é‡({len(weights)})åº”è¯¥æ¯”é˜ˆå€¼æ•°é‡({len(thresholds)})å¤š1")

    thresholds_tensor = torch.tensor(thresholds, device=target.device, dtype=target.dtype)
    weights_tensor = torch.tensor(weights, device=target.device, dtype=target.dtype)
    
    indices = torch.bucketize(target, thresholds_tensor)
    weight_map = weights_tensor[indices]
    
    return weight_map


class SparsePrecipitationLoss(nn.Module):
    """
    ç¨€ç–é™æ°´æŸå¤±å‡½æ•° - ä¸“ä¸ºä¿æŒé™æ°´é¢„æµ‹çš„ç¨€ç–æ€§è®¾è®¡ï¼Œä¸ Logit Space å’Œè£åˆ¤è¯„åˆ† W_k å¯¹é½ã€‚
    """
    
    def __init__(self, 
                 positive_weight: float = 100.0,
                 sparsity_weight: float = 5.0,     # ä¿®æ­£ï¼šé™ä½å¯¹è™šè­¦çš„æƒ©ç½šå¼ºåº¦
                 l1_weight: float = 0.5,           # ä¿®æ­£ï¼šL1 Hard Start æƒé‡
                 bce_weight: float = 8.0,
                 threshold: float = 0.01,
                 precipitation_thresholds: Optional[List[float]] = None,
                 precipitation_weights: Optional[List[float]] = None,
                 reduction: str = 'mean',
                 eps: float = 1e-6,
                 temporal_weight_enabled: bool = False,
                 temporal_weight_max: float = 2.0,
                 evolution_weight: float = 0.0,
                 ssim_weight: Optional[float] = 0.3,
                 temporal_consistency_weight: float = 0.1, # ä¿®æ­£ï¼šé™ä½å¹³æ»‘åå¥½
                 referee_weights_w_k: Optional[List[float]] = None):
        super(SparsePrecipitationLoss, self).__init__()
        
        self.positive_weight = positive_weight
        self.sparsity_weight = sparsity_weight
        self.l1_weight = l1_weight
        self.bce_weight = bce_weight
        self.threshold = threshold
        self.reduction = reduction
        self.eps = eps
        self.temporal_weight_enabled = temporal_weight_enabled
        self.temporal_weight_max = temporal_weight_max
        self.ssim_weight = ssim_weight if ssim_weight is not None and ssim_weight > 0 else None
        self.evolution_weight = evolution_weight
        if self.evolution_weight > 0:
            self.evo_loss = EvolutionLoss(weight=self.evolution_weight)
        else:
            self.evo_loss = None
        self.temporal_consistency_weight = temporal_consistency_weight
        
        # ğŸš¨ æ ¸å¿ƒä¿®æ­£: Logit Space Loss - BCEWithLogitsLoss æ›¿ä»£ MSELoss (BCEä»£ç†)
        self.bce_loss = nn.BCEWithLogitsLoss(reduction='none') 
        self.l1_loss = nn.L1Loss(reduction='none')

        # é™æ°´é˜ˆå€¼é…ç½®
        if precipitation_thresholds is None:
            # ç«èµ›é»˜è®¤é˜ˆå€¼ (å½’ä¸€åŒ–)
            self.precipitation_thresholds = [0.1/30.0, 1.0/30.0, 2.0/30.0, 5.0/30.0, 8.0/30.0]
            self.precipitation_weights = [1.0, 2.0, 5.0, 10.0, 20.0, 30.0] 
        else:
             self.precipitation_thresholds = precipitation_thresholds
             self.precipitation_weights = precipitation_weights
        
        # æ—¶åºæƒé‡ W_k
        if referee_weights_w_k is not None:
            self.register_buffer('w_k', torch.tensor(referee_weights_w_k, dtype=torch.float32).view(1, -1, 1, 1))
        else:
             self.w_k = None
        
        # MS-SSIM åˆå§‹åŒ–
        self.use_ssim = False
        if self.ssim_weight is not None and self.ssim_weight > 0 and TORCHMETRICS_AVAILABLE:
            self.use_ssim = True
            # Type assertion: MultiScaleStructuralSimilarityIndexMeasure is guaranteed to be available here
            assert MultiScaleStructuralSimilarityIndexMeasure is not None, "MultiScaleStructuralSimilarityIndexMeasure should be available when TORCHMETRICS_AVAILABLE is True"
            self.ms_ssim = MultiScaleStructuralSimilarityIndexMeasure(
                data_range=1.0, kernel_size=7, betas=(0.0448, 0.2856, 0.3001, 0.2363, 0.1333)[:3], normalize="relu"
            )
        else:
             self.ms_ssim = None


    def forward(self, logits_pred: torch.Tensor, target: torch.Tensor, target_mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        è®¡ç®—ç¨€ç–é™æ°´é¢„æµ‹çš„ç»„åˆæŸå¤±ã€‚
        Args:
            logits_pred: æ¨¡å‹è¾“å‡ºçš„ Logits Z (B, T, C, H, W)
            target: çœŸå®ç›®æ ‡å€¼ (B, T, C, H, W)
            target_mask: æ©ç  (B, T, C, H, W)
        """
        
        # 1. æ•°æ®ç»´åº¦å¤„ç† (å°† C ç»´åº¦å‹å¹³æˆ–ç§»é™¤ï¼Œé’ˆå¯¹ C=1 é™æ°´é€šé“)
        if len(logits_pred.shape) == 5:
            logits_pred_4d = logits_pred.squeeze(2) 
            target_4d = target.squeeze(2)
            target_mask_4d = target_mask.squeeze(2) if target_mask is not None else None
        else:
             logits_pred_4d = logits_pred
             target_4d = target
             target_mask_4d = target_mask

        # 2. æ ¸å¿ƒé¢„æµ‹ (Pred Space, [0, 1])
        # Pred ç”¨äº L1, SSIM, Sparsity æƒ©ç½š
        pred_4d = torch.sigmoid(logits_pred_4d)
        pred_clamped_4d = torch.clamp(pred_4d, 0.0, 1.0) 
        
        # 3. æŸå¤±é¡¹è®¡ç®— (åŸºç¡€æŸå¤±ï¼Œreduction='none')
        
        # L1 Loss (åœ¨ Pred Space, ä½¿ç”¨ clamped output)
        l1_comp = self.l1_loss(pred_clamped_4d, target_4d) 
        
        # BCE Loss (åœ¨ Logit Space, é¿å…æ¢¯åº¦æˆªæ–­)
        bce_comp = self.bce_loss(logits_pred_4d, target_4d) 

        # 4. åŠ¨æ€æƒé‡è®¡ç®— (Positive + Sparsity)
        
        # é™æ°´åŒºåŸŸæ©ç  (Positives)
        mask_pos = (target_4d > self.threshold)
        mask_neg = ~mask_pos

        # è™šè­¦åŒºåŸŸæ©ç  (False Positives): çœŸå®ä¸º0ï¼Œé¢„æµ‹é«˜äºé˜ˆå€¼
        mask_false_pos = torch.logical_and(mask_neg, pred_clamped_4d > self.threshold)
        
        # åˆå§‹åŒ–æƒé‡å›¾
        weight_map = torch.ones_like(target_4d, dtype=target_4d.dtype)
        
        # åº”ç”¨ Positive Weight
        weight_map[mask_pos] *= self.positive_weight
        
        # åº”ç”¨ Sparsity Weight (æƒ©ç½šè™šè­¦)
        weight_map[mask_false_pos] += self.sparsity_weight
        
        # 5. ç»„åˆåƒç´ çº§æŸå¤± (åŠ æƒ L1 + åŠ æƒ BCE)
        
        # æ ¸å¿ƒæŸå¤±é¡¹ï¼š(L1 * w_l1) + (BCE * w_bce)
        pixel_loss = l1_comp * self.l1_weight + bce_comp * self.bce_weight
        
        # åº”ç”¨åŠ¨æ€æƒé‡
        loss_weighted = pixel_loss * weight_map
        
        # 6. å½’çº¦å’Œæ—¶é—´æ­¥æƒé‡
        
        # åº”ç”¨ Target Mask (å¿½ç•¥æ— æ•ˆåŒºåŸŸ)
        if target_mask_4d is not None:
             valid_mask = target_mask_4d.bool() 
             loss_weighted = loss_weighted * valid_mask.float()
             count = valid_mask.sum() + self.eps 
        else:
             count = torch.numel(target_4d) + self.eps 
        
        # åº”ç”¨ W_k æ—¶é—´æƒé‡ (è£åˆ¤è¯„åˆ†æƒé‡)
        if self.w_k is not None:
             # ç¡®ä¿ w_k çš„æ—¶é—´ç»´åº¦ä¸æ•°æ®åŒ¹é… (T)
             time_weights_expanded = self.w_k.to(loss_weighted.device)
             loss_weighted = loss_weighted * time_weights_expanded 
        
        # æœ€ç»ˆå½’çº¦åˆ°å•ä¸ª Loss å€¼
        total_loss = loss_weighted.sum() / count

        # 7. ç»“æ„å’Œæ—¶åºæŸå¤± (ä½¿ç”¨ Pred Space Clampåçš„è¾“å‡º)
        
        # MS-SSIM Loss
        if self.use_ssim:
             ssim_score = self._compute_ssim_score(pred_clamped_4d, target_4d)
             ssim_loss_val = 1.0 - ssim_score
             total_loss += self.ssim_weight * ssim_loss_val

        # ğŸ†• åº”ç”¨ç‰©ç†æ¼”å˜æŸå¤± (Evolution Loss)
        if self.evo_loss is not None:
            # æ³¨æ„ï¼šå¿…é¡»ä¼ å…¥ [0,1] èŒƒå›´çš„é¢„æµ‹å€¼ (pred_clamped_4d)
            e_loss = self.evo_loss(pred_clamped_4d, target_4d)
            total_loss += e_loss
        
        # Temporal Consistency Loss
        if self.temporal_consistency_weight > 0:
             # æ³¨æ„: temporal_consistency_loss å†…éƒ¨é€šå¸¸ä¼šåš mean/sum å½’çº¦ï¼Œéœ€è¦è°¨æ…ä½¿ç”¨ä¹˜æ³•æƒé‡
             t_cons = temporal_consistency_loss(pred_clamped_4d.unsqueeze(2)) # ç¡®ä¿è¾“å…¥æ˜¯ 5D
             total_loss += self.temporal_consistency_weight * t_cons
        
        return total_loss
    
    
    def _compute_ssim_score(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        """è®¡ç®— MS-SSIM åˆ†æ•°ï¼ˆ1.0 æœ€å¥½ï¼‰"""
        H, W = pred.shape[-2:]
        if min(H, W) < 32: return torch.tensor(1.0, device=pred.device)

        # å¢åŠ é€šé“ç»´åº¦ C=1
        pred_flat = pred.view(-1, 1, H, W)
        target_flat = target.view(-1, 1, H, W)
        
        if self.ms_ssim is None: return torch.tensor(1.0, device=pred.device)
        
        try:
            self.ms_ssim = self.ms_ssim.to(pred.device)
            ssim_score = self.ms_ssim(pred_flat, target_flat)
            return ssim_score
        except Exception:
            return torch.tensor(1.0, device=pred.device)